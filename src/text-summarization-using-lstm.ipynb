{"cells":[{"cell_type":"markdown","metadata":{},"source":["## **Adding Requirement for Attention Layer**\n","\n","In our ongoing efforts to enhance our model's performance, we are introducing a crucial requirement: the incorporation of an attention layer. Attention mechanisms empower our model to dynamically focus on specific parts of the input sequence, significantly improving its contextual understanding and predictive accuracy.\n","\n","**Why Attention Matters:**\n","- Attention mechanisms allow the model to consider relevant information selectively.\n","- They enhance the model's ability to capture dependencies within the data.\n","- The result is improved performance and more accurate predictions.\n","\n","With the addition of this requirement, we are harnessing the power of attention mechanisms to elevate our model's capabilities and achieve superior outcomes.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'C:\\\\Users\\\\leosr\\\\OneDrive\\\\Desktop\\\\working\\\\attention.py'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from shutil import copyfile\n","copyfile(src = r\"C:\\Users\\leosr\\OneDrive\\Desktop\\input\\attention.py\", dst = r\"C:\\Users\\leosr\\OneDrive\\Desktop\\working\\attention.py\")"]},{"cell_type":"markdown","metadata":{},"source":["## **Importing Required Libraries**\n","\n","To kick off our project, it's essential to import the necessary libraries that will empower our code and streamline our development process.\n","\n","**Why Library Imports Matter:**\n","- Libraries provide pre-built functions and tools, saving us time and effort.\n","- They enable us to tap into the power of well-established code and best practices.\n","- Proper library usage enhances code readability and maintainability.\n","\n","In this step, we load the libraries that will lay the foundation for our project's success. Each import represents a building block toward achieving our goals efficiently and effectively.\n"]},{"cell_type":"code","execution_count":56,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"_Jpu8qLEFxcY","outputId":"95968e01-faac-4911-c802-9c008a4e62cf","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","import re\n","from nltk.corpus import stopwords\n","from bs4 import BeautifulSoup\n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from nltk.corpus import stopwords\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","from keras_self_attention import SeqSelfAttention\n","from tensorflow.keras.layers import Attention\n","\n","\n","\n","from attention import AttentionLayer\n","# from keras.layers import AttentionLayer\n","\n","\n","\n","import warnings\n","pd.set_option(\"display.max_colwidth\", 200)\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["## **Loading Dataset into the Notebook**\n","\n","In any data-driven project, one of the pivotal initial steps is loading the dataset into our working environment. This dataset serves as the raw material for our analysis, modeling, or other data-related tasks.\n","\n","**Why Dataset Loading Matters:**\n","- It grants us access to the information we'll be working with.\n","- Proper loading ensures data consistency and integrity.\n","- A well-organized dataset sets the stage for productive data exploration.\n","\n","In this phase, we import the dataset, laying the groundwork for our subsequent data processing and analysis. It's the point where our journey to insights and understanding begins.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"wnK5o4Z1Fxcj","trusted":true},"outputs":[],"source":["data=pd.read_csv(\"D:/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/Reviews/Reviews.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## **Data Cleaning: Removing Duplicate Reviews and Handling Null Values**\n","\n","In the process of preparing our dataset for analysis and modeling, it's essential to address data quality issues. This step involves handling two common data challenges: duplicates and missing values.\n","\n","**1. Dropping Duplicate Reviews:**\n","- Duplicate reviews, if left unattended, can skew our analysis and create bias.\n","- By identifying and removing duplicate reviews, we ensure that each data point contributes meaningfully to our insights.\n","\n","**2. Handling Null Values:**\n","- Null (or missing) values in the dataset can disrupt our calculations and visualizations.\n","- Effective handling, whether through imputation or removal, ensures our dataset remains coherent and accurate.\n","\n","Cleaning the data in this manner helps us maintain the dataset's quality and reliability, setting the stage for robust analysis and modeling.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Cjul88oOFxcr","trusted":true},"outputs":[],"source":["data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n","data.dropna(axis=0,inplace=True)#dropping na"]},{"cell_type":"markdown","metadata":{},"source":["## **Dataset Overview: Data Types and Shape**\n","\n","Before diving into data analysis and modeling, it's essential to gain a comprehensive understanding of the dataset. Let's begin by examining its data types and shape.\n","\n","**Data Types:**\n","- By inspecting the data types of each column, we can identify the nature of the information they hold.\n","- Understanding data types guides us in applying appropriate analysis techniques and transformations.\n","\n","**Shape of the Dataset:**\n","- Exploring the dimensions (number of rows and columns) of the dataset is crucial.\n","- It gives us an overview of the dataset's size, providing insights into the volume of data we're working with.\n","\n","This preliminary exploration sets the stage for further data preprocessing and analysis, ensuring that we're well-informed about the dataset's structure and characteristics.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"__fy-JxTFxc9","outputId":"d42c6e36-bbc8-43c2-de0e-d3effe3e8c4c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 393560 entries, 0 to 568453\n","Data columns (total 10 columns):\n"," #   Column                  Non-Null Count   Dtype \n","---  ------                  --------------   ----- \n"," 0   Id                      393560 non-null  int64 \n"," 1   ProductId               393560 non-null  object\n"," 2   UserId                  393560 non-null  object\n"," 3   ProfileName             393560 non-null  object\n"," 4   HelpfulnessNumerator    393560 non-null  int64 \n"," 5   HelpfulnessDenominator  393560 non-null  int64 \n"," 6   Score                   393560 non-null  int64 \n"," 7   Time                    393560 non-null  int64 \n"," 8   Summary                 393560 non-null  object\n"," 9   Text                    393560 non-null  object\n","dtypes: int64(5), object(5)\n","memory usage: 33.0+ MB\n"]}],"source":["data.info()"]},{"cell_type":"markdown","metadata":{},"source":["## **Creating a Contraction Dictionary**\n","\n","In natural language processing and text analytics, contractions can pose a challenge. To facilitate text preprocessing and analysis, we're establishing a contraction dictionary. This dictionary is designed to expand common contractions into their full forms.\n","\n","**Why Expand Contractions?**\n","- Expanding contractions allows for more consistent text processing.\n","- It simplifies subsequent tokenization, stemming, and analysis tasks.\n","\n","Our contraction dictionary will serve as a valuable tool for enhancing the accuracy and comprehensibility of textual data. It's an essential step in preparing the text for various NLP applications.\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"0s6IY-x2FxdL","trusted":true},"outputs":[],"source":["contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n","                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n","                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n","                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n","                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n","                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n","                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n","                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n","                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n","                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n","                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n","                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n","                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n","                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n","                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n","                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n","                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n","                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n","                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n","                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n","                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n","                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n","                           \"you're\": \"you are\", \"you've\": \"you have\"}"]},{"cell_type":"markdown","metadata":{},"source":["## **Removing Stopwords**\n","\n","Stopwords are common words in a language (e.g., \"the,\" \"and,\" \"in\") that are often removed from text data because they don't typically contribute significant meaning to the text. Removing stopwords is a common preprocessing step in natural language processing (NLP) tasks.\n","\n","**Why Remove Stopwords?**\n","- Enhances the efficiency of text analysis by reducing the size of the dataset.\n","- Focuses analysis on more meaningful words and phrases.\n","- Improves the accuracy of NLP models, as stopwords are usually not informative.\n","\n","By eliminating stopwords, we streamline the text data, making it more suitable for tasks like sentiment analysis, text classification, and topic modeling.\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# import nltk\n","# nltk.download(\"stopwords\")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"XZr-u3OEFxdT","trusted":true},"outputs":[],"source":["stop_words = set(stopwords.words('english')) "]},{"cell_type":"markdown","metadata":{},"source":["## **Cleaning Reviews and Summaries**\n","\n","Cleaning text data is an essential preprocessing step in natural language processing (NLP). This function focuses on cleaning both reviews and summaries to prepare the data for analysis and modeling.\n","\n","**What Does the Cleaning Function Do?**\n","- It removes any HTML tags or elements that might be present in the text.\n","- Expands contractions to improve text readability and consistency.\n","- Converts text to lowercase to ensure uniformity.\n","- Removes special characters and punctuations.\n","- Handles and standardizes whitespace.\n","- Removes stopwords, which are common words that don't carry significant meaning.\n","\n","By applying this cleaning function, we aim to make the text more suitable for NLP tasks such as sentiment analysis, text summarization, and more. Cleaned data helps improve the accuracy and effectiveness of NLP models and analyses.\n"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["def text_cleaner(text,num):\n","    newString = text.lower()\n","    newString = BeautifulSoup(newString, \"html5lib\").text\n","    newString = re.sub(r'\\([^)]*\\)', '', newString)\n","    newString = re.sub('\"','', newString)\n","    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n","    newString = re.sub(r\"'s\\b\",\"\",newString)\n","    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n","    newString = re.sub('[m]{2,}', 'mm', newString)\n","    if(num==0):\n","        tokens = [w for w in newString.split() if not w in stop_words]\n","    else:\n","        tokens=newString.split()\n","    long_words=[]\n","    for i in tokens:\n","        if len(i)>1:                                                 #removing short word\n","            long_words.append(i)   \n","    return (\" \".join(long_words)).strip()"]},{"cell_type":"markdown","metadata":{},"source":["## **Cleaning Reviews and Displaying**\n","\n","In this step, we apply the cleaning function to the reviews, which has several benefits:\n","- It enhances the quality of text data for further analysis.\n","- Removes unnecessary elements, special characters, and stopwords.\n","- Standardizes the text, making it more suitable for NLP tasks.\n","\n","After applying the cleaning process, we'll display the cleaned reviews. This allows us to inspect the transformed data and ensure that it's ready for subsequent analysis and modeling.\n","\n","By cleaning and displaying the reviews, we're taking a crucial step towards improving data quality and readability for NLP tasks such as sentiment analysis, text summarization, and more.\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"A2QAeCHWFxdY","trusted":true},"outputs":[{"data":{"text/plain":["['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n"," 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n"," 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n"," 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n"," 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["#call the function\n","cleaned_text = []\n","for t in data['Text']:\n","    cleaned_text.append(text_cleaner(t,0))\n","cleaned_text[:5]  "]},{"cell_type":"markdown","metadata":{},"source":["## **Cleaning Summaries and Displaying**\n","\n","In this step, we perform a similar cleaning process, but this time it's applied to the summaries. The objectives are as follows:\n","- Enhance the quality of the summary text for NLP tasks.\n","- Remove unnecessary elements, special characters, and stopwords.\n","- Standardize the text, making it more suitable for analysis and modeling.\n","\n","After the cleaning process is applied to the summaries, we'll display the cleaned summaries. This allows us to visually inspect the transformed data, ensuring that it's prepared for further NLP tasks, such as text summarization or sentiment analysis.\n","\n","Cleaning and displaying summaries are essential steps for achieving high-quality results in NLP projects. It ensures that the summary text is concise, readable, and well-prepared for subsequent analysis.\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"GsRXocxoFxd-","trusted":true},"outputs":[{"data":{"text/plain":["['good quality dog food',\n"," 'not as advertised',\n"," 'delight says it all',\n"," 'cough medicine',\n"," 'great taffy',\n"," 'nice taffy',\n"," 'great just as good as the expensive brands',\n"," 'wonderful tasty taffy',\n"," 'yay barley',\n"," 'healthy dog food']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["#call the function\n","cleaned_summary = []\n","for t in data['Summary']:\n","    cleaned_summary.append(text_cleaner(t,1))\n","cleaned_summary[:10]"]},{"cell_type":"markdown","metadata":{},"source":["## **Adding Columns to the Dataset**\n","\n","In this phase, we expand the dataset by adding new columns that provide valuable insights and metadata about the reviews and summaries. These additional columns serve various purposes, including:\n","\n","- **Text Lengths**: We calculate and append the length of the review and summary text in terms of the number of words. These lengths can be beneficial for analysis and visualizations.\n","  \n","- **Cleaned Text**: We integrate the cleaned versions of reviews and summaries into the dataset. These cleaned texts result from the previous data preprocessing steps, enhancing the quality and readiness of the data for natural language processing (NLP) tasks.\n","\n","- **Contractions Expanded**: The dataset now includes versions of the text with contractions expanded. This ensures that contractions (e.g., \"can't\" to \"cannot\") are properly represented for more accurate NLP analysis.\n","\n","- **Stopwords Removed**: To optimize NLP tasks, we provide versions of the text with common stopwords removed. Stopwords are words that don't typically carry significant meaning and are often removed during text analysis.\n","\n","These additional columns expand the dataset's capabilities, making it more suitable for various NLP applications, such as sentiment analysis, text summarization, or machine learning models.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"L1zLpnqsFxey","trusted":true},"outputs":[],"source":["data['cleaned_text']=cleaned_text\n","data['cleaned_summary']=cleaned_summary"]},{"cell_type":"markdown","metadata":{},"source":["## **Removing Empty Rows**\n","\n","In this step, we identify and eliminate empty or null rows within the dataset. Empty rows are often the result of missing or incomplete data and can hinder the quality of subsequent data analysis and modeling.\n","\n","The process of removing empty rows involves:\n","\n","- Identifying Rows: We scan the dataset to detect rows that contain no information or have missing values.\n","\n","- Filtering Data: Rows with missing or empty values are systematically filtered out from the dataset.\n","\n","- Dataset Integrity: This action helps ensure the integrity and consistency of the dataset, making it more suitable for various data analysis and modeling tasks.\n","\n","By eliminating empty rows, we improve the dataset's reliability, allowing for more accurate and meaningful insights during data analysis and modeling.\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"sYK390unFxfA","trusted":true},"outputs":[],"source":["data.replace('', np.nan, inplace=True)\n","data.dropna(axis=0,inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["## **Visualizing the Distribution of Reviews and Summaries**\n","\n","In this step, we aim to gain insights into the distribution of reviews and summaries within the dataset by creating visual representations. Visualization is a powerful tool for understanding data patterns and identifying potential trends.\n","\n","### **Visualization Techniques**\n","\n","We employ the following visualization techniques:\n","\n","1. **Histograms**: For reviews and summaries, we use histograms to display the frequency distribution of various lengths. This allows us to observe the most common review and summary lengths in the dataset.\n","\n","2. **Box Plots**: Box plots provide information about the spread and central tendency of review and summary lengths. They are particularly useful for identifying outliers and the overall distribution.\n","\n","By visualizing the data distribution, we can make informed decisions about data preprocessing and model design, leading to more effective text summarization.\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"MdF76AHHFxgw","outputId":"e3bbe165-4235-482f-bfd4-36a3f1d95290","trusted":true},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAGzCAYAAADDgXghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVpklEQVR4nO3dfVxUdd4//hcgM4A4IBoMJCKpqXiHYuJ044oiI7JdmuSqeRUa6UpMG8ymSZchaC1JeZei1JZi32RT23RLXGRCwMwRFSURbypXl3Z1wFVxFHVAOL8//HHWEzeCgjCc1/Px4FFzPu9z5v05ypmXM+fMsREEQQARERGRDNm2dQNEREREbYVBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiNqd/fv3IyEhAeXl5a32HDdu3EBCQgJyc3Nb7TmIiKj9YxCidmf//v1ITExs9SCUmJjIIEREJHMMQkRERO1URUVFW7fQ4TEIUbuSkJCA+fPnAwB8fX1hY2MDGxsbnDt3DgDw+eefIyAgAI6OjnBzc8P06dPxyy+/iOtv3LgRNjY22LBhg2S7f/rTn2BjY4Ndu3bh3LlzeOSRRwAAiYmJ4nMkJCQ8lDkS0b1du3YNMTEx6NWrF5RKJdzd3TF+/HgcOXIEANCrVy/MmjWrznpjxozBmDFjxMe5ubmwsbHB1q1bkZiYiEcffRRdunTB888/j6tXr8JisSAmJgbu7u5wdnbG7NmzYbFYJNu0sbGBTqfDtm3b4OfnB0dHR2g0GhQVFQEAPvroI/Tp0wcODg4YM2aMeLyq9d1332Hq1Kno2bMnlEolvL29ERsbi5s3b0rqZs2aBWdnZ5w5cwYTJ05Ely5dMHPmTCxevBj29va4ePFinfnOnTsXrq6uuHXr1n3sZQKATm3dANHdpkyZgh9//BF/+ctfsHLlSnTv3h0A8Mgjj+Ddd9/F22+/jd/97nd45ZVXcPHiRaxZswajR4/G0aNH4erqitmzZ+Orr76CXq/H+PHj4e3tjaKiIiQmJiIyMhITJ05ERUUF1q9fj6ioKDz33HOYMmUKAGDIkCFtOXUiusu8efPw5ZdfQqfTwc/PD5cuXcK+fftw8uRJDB8+vNnbS0pKgqOjIxYuXIiff/4Za9asgb29PWxtbXHlyhUkJCTgwIEDSEtLg6+vL+Lj4yXrf/fdd/j6668RHR0tbu+3v/0tFixYgHXr1uHVV1/FlStXkJycjJdffhl79uwR1922bRtu3LiBqKgodOvWDQcPHsSaNWvwr3/9C9u2bZM8z+3bt6HVavH000/jgw8+gJOTEzQaDZYsWYItW7ZAp9OJtZWVlfjyyy8RHh4OBweHZu8T+v8JRO3M+++/LwAQzp49Ky47d+6cYGdnJ7z77ruS2qKiIqFTp06S5RcuXBDc3NyE8ePHCxaLRRg2bJjQs2dP4erVq2LNxYsXBQDC4sWLW3s6RHQfXFxchOjo6AbHfXx8hIiIiDrLf/Ob3wi/+c1vxMc5OTkCAGHQoEFCZWWluHzGjBmCjY2NEBoaKllfo9EIPj4+kmUABKVSKTkmffTRRwIAQa1WC2azWVweFxdX5/h148aNOn0mJSUJNjY2wj//+U9xWUREhABAWLhwYZ16jUYjBAYGSpZ99dVXAgAhJyenTj01HT8aI6vw1VdfoaamBr/73e/wn//8R/xRq9Xo27cvcnJyxFq1Wo2UlBQYDAY888wzKCwsxIYNG6BSqdpwBkTUHK6ursjPz8f58+dbZHsvvfQS7O3txceBgYEQBAEvv/yypC4wMBC//PILbt++LVk+btw49OrVS1IHAOHh4ejSpUud5f/4xz/EZY6OjuL/V1RU4D//+Q+efPJJCIKAo0eP1uk1Kiqq3v7z8/Nx5swZcdnmzZvh7e2N3/zmN43OnRrHIERW4aeffoIgCOjbty8eeeQRyc/JkydRVlYmqZ8+fTrCwsJw8OBBzJkzB+PGjWujzonofiQnJ+P48ePw9vbGyJEjkZCQIAkXzdWzZ0/JYxcXFwCAt7d3neU1NTW4evXqfa8PAFeuXBGXlZSUYNasWXBzc4OzszMeeeQRMbz8+nk6deqEHj161Ol/2rRpUCqV2Lx5s7jezp07MXPmTNjY2DQyc7oXniNEVqGmpgY2Njb4+9//Djs7uzrjzs7OkseXLl3C4cOHAQAnTpxATU0NbG2Z+4msxe9+9zs888wz2L59O7KysvD+++9j2bJl+OqrrxAaGtrgi391dXW9x4j6ljW2XBCEFlm/uroa48ePx+XLl/Hmm2+if//+6Ny5M/79739j1qxZqKmpkaynVCrrPVZ17doVv/3tb7F582bEx8fjyy+/hMViwf/+7//W+/zUdAxC1O7Ud4Dr3bs3BEGAr68vHn/88XtuIzo6GteuXUNSUhLi4uKwatUq6PX6Rp+DiNoXT09PvPrqq3j11VdRVlaG4cOH491330VoaCi6du1a73eN/fOf/8Rjjz328JttQFFREX788Uds2rQJL730krjcYDA0e1svvfQSJk2ahEOHDmHz5s0YNmwYBg4c2JLtyhL/iUztTufOnQFAcpCbMmUK7OzskJiYWOdfaoIg4NKlS+LjL7/8Elu2bMF7772HhQsXYvr06Vi0aBF+/PFHscbJyanOcxBR+1BdXV3nIyN3d3d4eXmJl7b37t0bBw4cQGVlpVizc+dOyddptAe17xjdfdwSBAGrV69u9rZCQ0PRvXt3LFu2DHl5eXw3qIXwHSFqdwICAgAA//d//4fp06fD3t4ezz77LN555x3ExcXh3LlzmDx5Mrp06YKzZ89i+/btmDt3Lt544w2UlZUhKioKQUFB4mWma9euRU5ODmbNmoV9+/bB1tYWjo6O8PPzw5YtW/D444/Dzc0NgwYNwqBBg9py6kSEO98h1KNHDzz//PMYOnQonJ2d8e233+LQoUNYvnw5AOCVV17Bl19+iQkTJuB3v/sdzpw5g88//xy9e/du4+6l+vfvj969e+ONN97Av//9b6hUKvz1r3+VnEPUVPb29pg+fTrWrl0LOzs7zJgxoxU6lh++I0TtzhNPPIGlS5fihx9+wKxZszBjxgxcvHgRCxcuxF//+lfY2toiMTERb7zxBr7++muEhITgf/7nfwDcudrCYrGIX6wIAN26dcPHH38Mo9GIDz74QHyeTz75BI8++ihiY2MxY8YMfPnll20yXyKScnJywquvvorCwkIsXrwYsbGxOH36NNatWyd+xK3VarF8+XL8+OOPiImJgdFoxM6dO+s90bgt2dvb45tvvoG/vz+SkpKQmJiIvn374rPPPruv7dV+vDZu3Dh4enq2ZKuyZSP8+nMGIiIiapd++OEH+Pv747PPPsOLL77Y1u10CHxHiIiIyEr8+c9/hrOzs/iN+PTgeI4QERFRO/fNN9/gxIkT+Pjjj6HT6cSLSujB8aMxIiKidq5Xr14oLS2FVqvF//t//0/ybdb0YBiEiIiISLZ4jhARERHJFoMQERERyRZPlm5ETU0Nzp8/jy5duvCWDEQtTBAEXLt2DV5eXrK9DxyPMUStoznHFwahRpw/f77OnYWJqGX98ssv7e5L8B4WHmOIWldTji8MQo2oPSv/l19+gUqlarCuqqoKWVlZCAkJgb29/cNqr1VwLu1TR5yLRqOBr6+vrK9+qZ372bNnYTQaO8Sfb2vpSL8DrYH7R8psNsPb27tJx5dmBaH169dj/fr1OHfuHABg4MCBiI+PR2hoKABgzJgxyMvLk6zz+9//HqmpqeLjkpISREVFIScnB87OzoiIiEBSUhI6dfpvK7m5udDr9SguLoa3tzcWLVqEWbNmSbabkpKC999/HyaTCUOHDsWaNWswcuRIcfzWrVv44x//iC+++AIWiwVarRbr1q2Dh4dHk+db+1a1SqW6ZxBycnKCSqWy+r+AnEv71BHnUnuAkvNHQrVz79KlS4f5820tHel3oDVw/9SvKceXZn0w36NHD7z33nsoKCjA4cOHMXbsWEyaNAnFxcVizZw5c3DhwgXxJzk5WRyrrq5GWFgYKisrsX//fmzatAlpaWmIj48Xa86ePYuwsDAEBQWhsLAQMTExeOWVV7B7926xZsuWLdDr9Vi8eDGOHDmCoUOHQqvVoqysTKyJjY3FN998g23btiEvLw/nz5/nN3ESERGRRLOC0LPPPouJEyeib9++ePzxx/Huu+/C2dkZBw4cEGucnJygVqvFn7vfScnKysKJEyfw+eefw9/fH6GhoVi6dClSUlJQWVkJAEhNTYWvry+WL1+OAQMGQKfT4fnnn8fKlSvF7axYsQJz5szB7Nmz4efnh9TUVDg5OWHDhg0AgKtXr+LTTz/FihUrMHbsWAQEBGDjxo3Yv3+/pFciIiKSt/s+R6i6uhrbtm1DRUUFNBqNuHzz5s34/PPPoVar8eyzz+Ltt9+Gk5MTAMBoNGLw4MGSj6e0Wi2ioqJQXFyMYcOGwWg0Ijg4WPJcWq0WMTExAIDKykoUFBQgLi5OHLe1tUVwcDCMRiMAoKCgAFVVVZLt9O/fHz179oTRaMSoUaPqnZPFYoHFYhEfm81mAHfecqyqqmpwX9SONVZjLTiX9olzISJqHc0OQkVFRdBoNLh16xacnZ2xfft2+Pn5AQBeeOEF+Pj4wMvLC8eOHcObb76J06dP46uvvgIAmEymOufo1D42mUyN1pjNZty8eRNXrlxBdXV1vTWnTp0St6FQKODq6lqnpvZ56pOUlITExMQ6y7OyssQw1xiDwXDPGmvBubRPHWkuOTk5bd0CEVHzg1C/fv1QWFiIq1ev4ssvv0RERATy8vLg5+eHuXPninWDBw+Gp6cnxo0bhzNnzqB3794t2nhriIuLg16vFx/XnnUeEhJyz5OlDQYDxo8fb/UnqXEu7VNHnEtQUFBbt0JE1PwgpFAo0KdPHwBAQEAADh06hNWrV+Ojjz6qUxsYGAgA+Pnnn9G7d2+o1WocPHhQUlNaWgoAUKvV4n9rl91do1Kp4OjoCDs7O9jZ2dVbc/c2KisrUV5eLnlX6O6a+iiVSiiVyjrL7e3tm/Ti09Q6a8C5tE8dbS5ERG3tgb/OtaamRnJezd0KCwsBAJ6engAAjUaDoqIiydVdBoMBKpVK/HhNo9EgOztbsh2DwSCeh6RQKBAQECCpqampQXZ2tlgTEBAAe3t7Sc3p06dRUlIiOZ+JiIiI5K1Z7wjFxcUhNDQUPXv2xLVr15Ceno7c3Fzs3r0bZ86cQXp6OiZOnIhu3brh2LFjiI2NxejRozFkyBAAQEhICPz8/PDiiy8iOTkZJpMJixYtQnR0tPhOzLx587B27VosWLAAL7/8Mvbs2YOtW7ciIyND7EOv1yMiIgIjRozAyJEjsWrVKlRUVGD27NkAABcXF0RGRkKv18PNzQ0qlQqvvfYaNBpNgydKExERkfw0KwiVlZXhpZdewoULF+Di4oIhQ4Zg9+7dGD9+PH755Rd8++23Yijx9vZGeHg4Fi1aJK5vZ2eHnTt3IioqChqNBp07d0ZERASWLFki1vj6+iIjIwOxsbFYvXo1evTogU8++QRarVasmTZtGi5evIj4+HiYTCb4+/sjMzNTcgL1ypUrYWtri/DwcMkXKhIRERHValYQ+vTTTxsc8/b2rvOt0vXx8fHBrl27Gq0ZM2YMjh492miNTqeDTqdrcNzBwQEpKSlISUm5Z09EREQkT/K85TMRERERGISIiIhIxhiEiIiISLYYhIiIiEi27vteY1TXoITdsFTb1Fl+7r2wNuiGiOSg18KMBsd47CG6N74jRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERWo7q6Gm+//TZ8fX3h6OiI3r17Y+nSpRAEQawRBAHx8fHw9PSEo6MjgoOD8dNPP0m2c/nyZcycORMqlQqurq6IjIzE9evXJTXHjh3DM888AwcHB3h7eyM5OblOP9u2bUP//v3h4OCAwYMHY9euXa0zcSJqNQxCRGQ1li1bhvXr12Pt2rU4efIkli1bhuTkZKxZs0asSU5OxocffojU1FTk5+ejc+fO0Gq1uHXrllgzc+ZMFBcXw2AwYOfOndi7dy/mzp0rjpvNZoSEhMDHxwcFBQV4//33kZCQgI8//lis2b9/P2bMmIHIyEgcPXoUkydPxuTJk3H8+PGHszOIqEUwCBGR1di/fz8mTZqEsLAw9OrVC88//zxCQkJw8OBBAHfeDVq1ahUWLVqESZMmYciQIfjss89w/vx57NixAwBw8uRJZGZm4pNPPkFgYCCefvpprFmzBl988QXOnz8PANi8eTMqKyuxYcMGDBw4ENOnT8cf/vAHrFixQuxl9erVmDBhAubPn48BAwZg6dKlGD58ONauXfvQ9wsR3b9Obd0AEVFTPfnkk/j444/x448/4vHHH8cPP/yAffv2iQHl7NmzMJlMCA4OFtdxcXFBYGAgjEYjpk+fDqPRCFdXV4wYMUKsCQ4Ohq2tLfLz8/Hcc8/BaDRi9OjRUCgUYo1Wq8WyZctw5coVdO3aFUajEXq9XtKfVqsVA1d9LBYLLBaL+NhsNgMAqqqqJP9tDqWd0ODY/WyvvXqQfSQH3D9SzdkPDEJEZDUWLlwIs9mM/v37w87ODtXV1Xj33Xcxc+ZMAIDJZAIAeHh4SNbz8PAQx0wmE9zd3SXjnTp1gpubm6TG19e3zjZqx7p27QqTydTo89QnKSkJiYmJdZbn5OTAyckJBoPhnvvg15JHNjzWEc9Zup99JCfcP3fcuHGjybUMQkRkNbZu3YrNmzcjPT0dAwcORGFhIWJiYuDl5YWIiIi2bu+e4uLiJO8imc1meHt7IygoCPn5+Rg/fjzs7e2btc1BCbsbHDueoL3vXtubqqoqGAyG+9pHcsD9I1X7bmtTMAgRkdWYP38+Fi5ciOnTpwMABg8ejH/+859ISkpCREQE1Go1AKC0tBSenp7ieqWlpfD39wcAqNVqlJWVSbZ7+/ZtXL58WVxfrVajtLRUUlP7+F41teP1USqVUCqVdZbXvnDZ29s3+0XMUm3T4FhHfEG8n30kJ9w/dzRnH/BkaSKyGjdu3ICtrfSwZWdnh5qaGgCAr68v1Go1srOzxXGz2Yz8/HxoNBoAgEajQXl5OQoKCsSaPXv2oKamBoGBgWLN3r17JecZGAwG9OvXD127dhVr7n6e2pra5yEi68AgRERW49lnn8W7776LjIwMnDt3Dtu3b8eKFSvw3HPPAQBsbGwQExODd955B19//TWKiorw0ksvwcvLC5MnTwYADBgwABMmTMCcOXNw8OBBfP/999DpdJg+fTq8vLwAAC+88AIUCgUiIyNRXFyMLVu2YPXq1ZKPtV5//XVkZmZi+fLlOHXqFBISEnD48GHodLqHvl+I6P7xozEishpr1qzB22+/jVdffRVlZWXw8vLC73//e8THx4s1CxYsQEVFBebOnYvy8nI8/fTTyMzMhIODg1izefNm6HQ6jBs3Dra2tggPD8eHH34ojru4uCArKwvR0dEICAhA9+7dER8fL/muoSeffBLp6elYtGgR3nrrLfTt2xc7duzAoEGDHs7OIKIWwSBERFajS5cuWLVqFVatWtVgjY2NDZYsWYIlS5Y0WOPm5ob09PRGn2vIkCH47rvvGq2ZOnUqpk6d2mgNEbVv/GiMiIiIZKtZQWj9+vUYMmQIVCoVVCoVNBoN/v73v4vjt27dQnR0NLp16wZnZ2eEh4fXuaqipKQEYWFhcHJygru7O+bPn4/bt29LanJzczF8+HAolUr06dMHaWlpdXpJSUlBr1694ODggMDAQPGbZZvTCxEREclbs4JQjx498N5776GgoACHDx/G2LFjMWnSJBQXFwMAYmNj8c0332Dbtm3Iy8vD+fPnMWXKFHH96upqhIWFobKyEvv378emTZuQlpYm+Xz/7NmzCAsLQ1BQkPgdIa+88gp27/7vd2Vs2bIFer0eixcvxpEjRzB06FBotVrJJbH36oWIiIioWUHo2WefxcSJE9G3b188/vjjePfdd+Hs7IwDBw7g6tWr+PTTT7FixQqMHTsWAQEB2LhxI/bv348DBw4AALKysnDixAl8/vnn8Pf3R2hoKJYuXYqUlBRUVlYCAFJTU+Hr64vly5djwIAB0Ol0eP7557Fy5UqxjxUrVmDOnDmYPXs2/Pz8kJqaCicnJ2zYsAEAmtQLERER0X2fLF1dXY1t27ahoqICGo0GBQUFqKqqktzjp3///ujZsyeMRiNGjRoFo9GIwYMHS76WXqvVIioqCsXFxRg2bBiMRqNkG7U1MTExAIDKykoUFBQgLi5OHLe1tUVwcDCMRiMANKmX+jR2H6DG7ltSO6a0rf+eP9Z075eOdL8azqV96khzISLr1+wgVFRUBI1Gg1u3bsHZ2Rnbt2+Hn58fCgsLoVAo4OrqKqn/9T1+6rs3T+1YYzVmsxk3b97ElStXUF1dXW/NqVOnxG3cq5f6NHQfoKysLDg5OTW4Xq2lI2rqXW6N9/vpSPer4Vzap5ycnLZugYio+UGoX79+KCwsxNWrV/Hll18iIiICeXl5rdHbQ9fQfYBCQkKgUqkaXK/2Hi9vH7aFpabu191b0/1+OtL9ajiX9ql2LkFBQW3dChFR84OQQqFAnz59AAABAQE4dOgQVq9ejWnTpqGyshLl5eWSd2LuvveOWq2uc3VXU+/fo1Kp4OjoCDs7O9jZ2TV6jx+1Wn3PXurT2H2AmvLiY6mxqfe+P9b4wtWR7lfDubRPHWUeRGTdHvh7hGpqamCxWBAQEAB7e3vJvXdOnz6NkpISyT1+ioqKJFd3GQwGqFQq+Pn5iTWN3b9HoVAgICBAUlNTU4Ps7Gyxpim9EBERETXrHaG4uDiEhoaiZ8+euHbtGtLT05Gbm4vdu3fDxcUFkZGR0Ov1cHNzg0qlwmuvvQaNRiOenBwSEgI/Pz+8+OKLSE5OhslkwqJFixAdHS2+EzNv3jysXbsWCxYswMsvv4w9e/Zg69atyMjIEPvQ6/WIiIjAiBEjMHLkSKxatQoVFRWYPXs2ADSpFyIiIqJmBaGysjK89NJLuHDhAlxcXDBkyBDs3r0b48ePBwCsXLlSvG+PxWKBVqvFunXrxPXt7Oywc+dOREVFQaPRoHPnzoiIiJB8Fb6vry8yMjIQGxuL1atXo0ePHvjkk0+g1f73PJtp06bh4sWLiI+Ph8lkgr+/PzIzMyUnUN+rFyIiIqJmBaFPP/200XEHBwekpKQgJSWlwRofH597XkU1ZswYHD16tNEanU7X6F2em9ILERERyRvvNUZERESyxbvPExF1UL0WZtS7/Nx7YQ+5E6L2i+8IERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDUrCCUlJeGJJ55Aly5d4O7ujsmTJ+P06dOSmjFjxsDGxkbyM2/ePElNSUkJwsLC4OTkBHd3d8yfPx+3b9+W1OTm5mL48OFQKpXo06cP0tLS6vSTkpKCXr16wcHBAYGBgTh48KBk/NatW4iOjka3bt3g7OyM8PBwlJaWNmfKRERE1IE1Kwjl5eUhOjoaBw4cgMFgQFVVFUJCQlBRUSGpmzNnDi5cuCD+JCcni2PV1dUICwtDZWUl9u/fj02bNiEtLQ3x8fFizdmzZxEWFoagoCAUFhYiJiYGr7zyCnbv3i3WbNmyBXq9HosXL8aRI0cwdOhQaLValJWViTWxsbH45ptvsG3bNuTl5eH8+fOYMmVKs3cSERERdUydmlOcmZkpeZyWlgZ3d3cUFBRg9OjR4nInJyeo1ep6t5GVlYUTJ07g22+/hYeHB/z9/bF06VK8+eabSEhIgEKhQGpqKnx9fbF8+XIAwIABA7Bv3z6sXLkSWq0WALBixQrMmTMHs2fPBgCkpqYiIyMDGzZswMKFC3H16lV8+umnSE9Px9ixYwEAGzduxIABA3DgwAGMGjWqTm8WiwUWi0V8bDabAQBVVVWoqqpqcL/UjilthUbHrUFtr9bUc0M4l/apI82FiKxfs4LQr129ehUA4ObmJlm+efNmfP7551Cr1Xj22Wfx9ttvw8nJCQBgNBoxePBgeHh4iPVarRZRUVEoLi7GsGHDYDQaERwcLNmmVqtFTEwMAKCyshIFBQWIi4sTx21tbREcHAyj0QgAKCgoQFVVlWQ7/fv3R8+ePWE0GusNQklJSUhMTKyzPCsrS+y/MUtH1NS7fNeuXfdct70xGAxt3UKL4Vzap5ycnLZugYjo/oNQTU0NYmJi8NRTT2HQoEHi8hdeeAE+Pj7w8vLCsWPH8Oabb+L06dP46quvAAAmk0kSggCIj00mU6M1ZrMZN2/exJUrV1BdXV1vzalTp8RtKBQKuLq61qmpfZ5fi4uLg16vFx+bzWZ4e3sjJCQEKpWqwX1RVVUFg8GAtw/bwlJjU2f8eIK2wXXbm9q5jB8/Hvb29m3dzgPhXNqn2rkEBQW1dStERPcfhKKjo3H8+HHs27dPsnzu3Lni/w8ePBienp4YN24czpw5g969e99/pw+BUqmEUqmss9ze3r5JLz6WGhtYqusGIWt84WrqnK0B59I+dZR5EJF1u6/L53U6HXbu3ImcnBz06NGj0drAwEAAwM8//wwAUKvVda7cqn1ce15RQzUqlQqOjo7o3r077Ozs6q25exuVlZUoLy9vsIaIiIjkrVlBSBAE6HQ6bN++HXv27IGvr+891yksLAQAeHp6AgA0Gg2KiookV3cZDAaoVCr4+fmJNdnZ2ZLtGAwGaDQaAIBCoUBAQICkpqamBtnZ2WJNQEAA7O3tJTWnT59GSUmJWENERETy1qyPxqKjo5Geno6//e1v6NKli3iujYuLCxwdHXHmzBmkp6dj4sSJ6NatG44dO4bY2FiMHj0aQ4YMAQCEhITAz88PL774IpKTk2EymbBo0SJER0eLH0vNmzcPa9euxYIFC/Dyyy9jz5492Lp1KzIyMsRe9Ho9IiIiMGLECIwcORKrVq1CRUWFeBWZi4sLIiMjodfr4ebmBpVKhddeew0ajabeE6WJiIhIfpoVhNavXw/gzpcm3m3jxo2YNWsWFAoFvv32WzGUeHt7Izw8HIsWLRJr7ezssHPnTkRFRUGj0aBz586IiIjAkiVLxBpfX19kZGQgNjYWq1evRo8ePfDJJ5+Il84DwLRp03Dx4kXEx8fDZDLB398fmZmZkhOoV65cCVtbW4SHh8NisUCr1WLdunXN2kFERETUcTUrCAlC/d+TU8vb2xt5eXn33I6Pj889LykfM2YMjh492miNTqeDTqdrcNzBwQEpKSlISUm5Z09EREQkP7zXGBEREckWgxARERHJFoMQERERyRaDEBEREcnWA91rjIiIrE+vhRkNjp17L+whdkLU9viOEBEREckWgxARWZV///vf+N///V9069YNjo6OGDx4MA4fPiyOC4KA+Ph4eHp6wtHREcHBwfjpp58k27h8+TJmzpwJlUoFV1dXREZG4vr165KaY8eO4ZlnnoGDgwO8vb2RnJxcp5dt27ahf//+cHBwwODBg+/5tSBE1P4wCBGR1bhy5Qqeeuop2Nvb4+9//ztOnDiB5cuXo2vXrmJNcnIyPvzwQ6SmpiI/Px+dO3eGVqvFrVu3xJqZM2eiuLgYBoMBO3fuxN69eyU3jDabzQgJCYGPjw8KCgrw/vvvIyEhAR9//LFYs3//fsyYMQORkZE4evQoJk+ejMmTJ+P48eMPZ2cQUYvgOUJEZDWWLVsGb29vbNy4UVx29z0PBUHAqlWrsGjRIkyaNAkA8Nlnn8HDwwM7duzA9OnTcfLkSWRmZuLQoUMYMWIEAGDNmjWYOHEiPvjgA3h5eWHz5s2orKzEhg0boFAoMHDgQBQWFmLFihViYFq9ejUmTJiA+fPnAwCWLl0Kg8GAtWvXIjU19WHtEiJ6QAxCRGQ1vv76a2i1WkydOhV5eXl49NFH8eqrr2LOnDkAgLNnz8JkMiE4OFhcx8XFBYGBgTAajZg+fTqMRiNcXV3FEAQAwcHBsLW1RX5+Pp577jkYjUaMHj0aCoVCrNFqtVi2bBmuXLmCrl27wmg0Qq/XS/rTarXYsWNHg/1bLBZYLBbxsdlsBgBUVVVJ/tscSrvGv/G/ue6nh4fhQfaRHHD/SDVnPzAIEZHV+Mc//oH169dDr9fjrbfewqFDh/CHP/wBCoUCERER4o2g777nYO3j2jGTyQR3d3fJeKdOneDm5iapufudpru3aTKZ0LVrV5hMpkafpz5JSUlITEysszwnJwdOTk4wGAxN2Q0SySObvUqj2vt5Tvezj+SE++eOGzduNLmWQYiIrEZNTQ1GjBiBP/3pTwCAYcOG4fjx40hNTUVEREQbd3dvcXFxkneRzGYzvL29ERQUhPz8fIwfPx729vbN2uaghN0t2uPxBO29i9pAVVUVDAbDfe0jOeD+kap9t7UpGISIyGp4enrCz89PsmzAgAH461//CgBQq9UAgNLSUnh6eoo1paWl8Pf3F2vKysok27h9+zYuX74srq9Wq1FaWiqpqX18r5ra8foolUoolco6y2tfuOzt7Zv9ImaptmlW/b209xfR+9lHcsL9c0dz9gGvGiMiq/HUU0/h9OnTkmU//vgjfHx8ANw5cVqtViM7O1scN5vNyM/Ph0ajAQBoNBqUl5ejoKBArNmzZw9qamoQGBgo1uzdu1dynoHBYEC/fv3EK9Q0Go3keWprap+HiKwDgxARWY3Y2FgcOHAAf/rTn/Dzzz8jPT0dH3/8MaKjowEANjY2iImJwTvvvIOvv/4aRUVFeOmll+Dl5YXJkycDuPMO0oQJEzBnzhwcPHgQ33//PXQ6HaZPnw4vLy8AwAsvvACFQoHIyEgUFxdjy5YtWL16teRjrddffx2ZmZlYvnw5Tp06hYSEBBw+fBg6ne6h7xciun/8aIyIrMYTTzyB7du3Iy4uDkuWLIGvry9WrVqFmTNnijULFixARUUF5s6di/Lycjz99NPIzMyEg4ODWLN582bodDqMGzcOtra2CA8Px4cffiiOu7i4ICsrC9HR0QgICED37t0RHx8v+a6hJ598Eunp6Vi0aBHeeust9O3bFzt27MCgQYMezs4gohbBIEREVuW3v/0tfvvb3zY4bmNjgyVLlmDJkiUN1ri5uSE9Pb3R5xkyZAi+++67RmumTp2KqVOnNt4wEbVr/GiMiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhkq1lBKCkpCU888QS6dOkCd3d3TJ48GadPn5bU3Lp1C9HR0ejWrRucnZ0RHh6O0tJSSU1JSQnCwsLg5OQEd3d3zJ8/H7dv35bU5ObmYvjw4VAqlejTpw/S0tLq9JOSkoJevXrBwcEBgYGBOHjwYLN7ISIiIvlqVhDKy8tDdHQ0Dhw4AIPBgKqqKoSEhKCiokKsiY2NxTfffINt27YhLy8P58+fx5QpU8Tx6upqhIWFobKyEvv378emTZuQlpaG+Ph4sebs2bMICwtDUFAQCgsLERMTg1deeQW7d+8Wa7Zs2QK9Xo/FixfjyJEjGDp0KLRaLcrKyprcCxEREclbp+YUZ2ZmSh6npaXB3d0dBQUFGD16NK5evYpPP/0U6enpGDt2LABg48aNGDBgAA4cOIBRo0YhKysLJ06cwLfffgsPDw/4+/tj6dKlePPNN5GQkACFQoHU1FT4+vpi+fLlAIABAwZg3759WLlyJbRaLQBgxYoVmDNnDmbPng0ASE1NRUZGBjZs2ICFCxc2qZdfs1gssFgs4mOz2QwAqKqqQlVVVYP7pXZMaSs0Om4Nanu1pp4bwrm0Tx1pLkRk/ZoVhH7t6tWrAAA3NzcAQEFBAaqqqhAcHCzW9O/fHz179oTRaMSoUaNgNBoxePBgeHh4iDVarRZRUVEoLi7GsGHDYDQaJduorYmJiQEAVFZWoqCgAHFxceK4ra0tgoODYTQam9zLryUlJSExMbHO8qysLDg5Od1zfywdUVPv8l27dt1z3fbGYDC0dQsthnNpn3Jyctq6BSKi+w9CNTU1iImJwVNPPYVBgwYBAEwmExQKBVxdXSW1Hh4eMJlMYs3dIah2vHassRqz2YybN2/iypUrqK6urrfm1KlTTe7l1+Li4qDX68XHZrMZ3t7eCAkJgUqlanBfVFVVwWAw4O3DtrDU2NQZP56gbXDd9qZ2LuPHj4e9vX1bt/NAOJf2qXYuQUFBbd0KEdH9B6Ho6GgcP34c+/bta8l+2pRSqYRSqayz3N7evkkvPpYaG1iq6wYha3zhauqcrQHn0j51lHkQkXW7r8vndToddu7ciZycHPTo0UNcrlarUVlZifLyckl9aWkp1Gq1WPPrK7dqH9+rRqVSwdHREd27d4ednV29NXdv4169EBERkbw1KwgJggCdToft27djz5498PX1lYwHBATA3t4e2dnZ4rLTp0+jpKQEGo0GAKDRaFBUVCS5ustgMEClUsHPz0+suXsbtTW121AoFAgICJDU1NTUIDs7W6xpSi9EREQkb836aCw6Ohrp6en429/+hi5duojn2ri4uMDR0REuLi6IjIyEXq+Hm5sbVCoVXnvtNWg0GvHk5JCQEPj5+eHFF19EcnIyTCYTFi1ahOjoaPFjqXnz5mHt2rVYsGABXn75ZezZswdbt25FRkaG2Iter0dERARGjBiBkSNHYtWqVaioqBCvImtKL0RERCRvzQpC69evBwCMGTNGsnzjxo2YNWsWAGDlypWwtbVFeHg4LBYLtFot1q1bJ9ba2dlh586diIqKgkajQefOnREREYElS5aINb6+vsjIyEBsbCxWr16NHj164JNPPhEvnQeAadOm4eLFi4iPj4fJZIK/vz8yMzMlJ1DfqxciIiKSt2YFIUGo/3ty7ubg4ICUlBSkpKQ0WOPj43PPS8rHjBmDo0ePNlqj0+mg0+keqBciIiKSL95rjIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhkq1NbN0BERO1Hr4UZ9S4/917YQ+6E6OHgO0JEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRERCRbDEJEREQkWwxCREREJFsMQkRktd577z3Y2NggJiZGXHbr1i1ER0ejW7ducHZ2Rnh4OEpLSyXrlZSUICwsDE5OTnB3d8f8+fNx+/ZtSU1ubi6GDx8OpVKJPn36IC0trc7zp6SkoFevXnBwcEBgYCAOHjzYGtNEr4UZDf4Q0YNhECIiq3To0CF89NFHGDJkiGR5bGwsvvnmG2zbtg15eXk4f/48pkyZIo5XV1cjLCwMlZWV2L9/PzZt2oS0tDTEx8eLNWfPnkVYWBiCgoJQWFiImJgYvPLKK9i9e7dYs2XLFuj1eixevBhHjhzB0KFDodVqUVZW1vqTJ6IW06mtGyAiaq7r169j5syZ+POf/4x33nlHXH716lV8+umnSE9Px9ixYwEAGzduxIABA3DgwAGMGjUKWVlZOHHiBL799lt4eHjA398fS5cuxZtvvomEhAQoFAqkpqbC19cXy5cvBwAMGDAA+/btw8qVK6HVagEAK1aswJw5czB79mwAQGpqKjIyMrBhwwYsXLiw3r4tFgssFov42Gw2AwCqqqok//01pZ3wILurRTTU28N+/rbuo73i/pFqzn5gECIiqxMdHY2wsDAEBwdLglBBQQGqqqoQHBwsLuvfvz969uwJo9GIUaNGwWg0YvDgwfDw8BBrtFotoqKiUFxcjGHDhsFoNEq2UVtT+xFcZWUlCgoKEBcXJ47b2toiODgYRqOxwb6TkpKQmJhYZ3lOTg6cnJxgMBjqXS95ZOP742HYtWtXW7cAAA3uI7qD++eOGzduNLmWQYiIrMoXX3yBI0eO4NChQ3XGTCYTFAoFXF1dJcs9PDxgMpnEmrtDUO147VhjNWazGTdv3sSVK1dQXV1db82pU6ca7D0uLg56vV58bDab4e3tjaCgIOTn52P8+PGwt7evs96ghN11lj1sxxO0bfr8VVVVMBgMDe4jueP+kap9t7UpGISIyGr88ssveP3112EwGODg4NDW7TSbUqmEUqmss7z2hcve3r7eFzFLtU2r93Yv7eXFtaF9RHdw/9zRnH3Q7JOl9+7di2effRZeXl6wsbHBjh07JOOzZs2CjY2N5GfChAmSmsuXL2PmzJlQqVRwdXVFZGQkrl+/Lqk5duwYnnnmGTg4OMDb2xvJycl1etm2bRv69+8PBwcHDB48uM5bt4IgID4+Hp6ennB0dERwcDB++umn5k6ZiNqJgoIClJWVYfjw4ejUqRM6deqEvLw8fPjhh+jUqRM8PDxQWVmJ8vJyyXqlpaVQq9UAALVaXecqstrH96pRqVRwdHRE9+7dYWdnV29N7TaIyDo0OwhVVFRg6NChSElJabBmwoQJuHDhgvjzl7/8RTI+c+ZMFBcXw2AwYOfOndi7dy/mzp0rjpvNZoSEhMDHxwcFBQV4//33kZCQgI8//lis2b9/P2bMmIHIyEgcPXoUkydPxuTJk3H8+HGxJjk5GR9++CFSU1ORn5+Pzp07Q6vV4tatW82dNhG1A+PGjUNRUREKCwvFnxEjRmDmzJni/9vb2yM7O1tc5/Tp0ygpKYFGowEAaDQaFBUVSa7uMhgMUKlU8PPzE2vu3kZtTe02FAoFAgICJDU1NTXIzs4Wa4jIOjT7o7HQ0FCEhoY2WqNUKhv8V9HJkyeRmZmJQ4cOYcSIEQCANWvWYOLEifjggw/g5eWFzZs3o7KyEhs2bIBCocDAgQNRWFiIFStWiIFp9erVmDBhAubPnw8AWLp0KQwGA9auXYvU1FQIgoBVq1Zh0aJFmDRpEgDgs88+g4eHB3bs2IHp06fX6a2xKzoaOwO9dkxpW/+VHdZ0Fn9HuvKAc2mfHmQuXbp0waBBgyTLOnfujG7duonLIyMjodfr4ebmBpVKhddeew0ajQajRo0CAISEhMDPzw8vvvgikpOTYTKZsGjRIkRHR4sfW82bNw9r167FggUL8PLLL2PPnj3YunUrMjL++709er0eERERGDFiBEaOHIlVq1ahoqJCvIqMiKxDq5wjlJubC3d3d3Tt2hVjx47FO++8g27dugEAjEYjXF1dxRAEAMHBwbC1tUV+fj6ee+45GI1GjB49GgqFQqzRarVYtmwZrly5gq5du8JoNEpOOqytqf2o7uzZszCZTJIrP1xcXBAYGAij0VhvEGroio6srCw4OTndc95LR9TUu7y9XG3RHB3pygPOpX3Kyclple2uXLkStra2CA8Ph8VigVarxbp168RxOzs77Ny5E1FRUdBoNOjcuTMiIiKwZMkSscbX1xcZGRmIjY3F6tWr0aNHD3zyySfipfMAMG3aNFy8eBHx8fEwmUzw9/dHZmZmnROoiah9a/EgNGHCBEyZMgW+vr44c+YM3nrrLYSGhsJoNMLOzg4mkwnu7u7SJjp1gpubm+SKDV9fX0nN3Vd1dO3atcGrOu7ext3r1Vfzaw1d0RESEgKVStXgnGvP1n/7sC0sNXVPamzrqy2aoyNdecC5tE+1cwkKCmqR7eXm5koeOzg4ICUlpdGP7318fO75D5QxY8bg6NGjjdbodDrodLom90pE7U+LB6G732kZPHgwhgwZgt69eyM3Nxfjxo1r6adrUY1d0dGUFx9LjU29V3dY4wtXR7rygHNpnzrKPIjIurX6LTYee+wxdO/eHT///DOAO1dj/Por6G/fvo3Lly+3yFUdd4/fvV59NURERCRvrR6E/vWvf+HSpUvw9PQEcOdqjPLychQUFIg1e/bsQU1NDQIDA8WavXv3Sk6mNBgM6NevH7p27SrWNHZVh6+vL9RqtaTGbDYjPz+fV3UQERERgPsIQtevXxcvWwXunJRcWFiIkpISXL9+HfPnz8eBAwdw7tw5ZGdnY9KkSejTp494kuGAAQMwYcIEzJkzBwcPHsT3338PnU6H6dOnw8vLCwDwwgsvQKFQIDIyEsXFxdiyZQtWr14tOX/n9ddfR2ZmJpYvX45Tp04hISEBhw8fFj+vr70j9TvvvIOvv/4aRUVFeOmll+Dl5YXJkyc/4G4jIiKijqDZ5wgdPnxYcpJjbTiJiIjA+vXrcezYMWzatAnl5eXw8vJCSEgIli5dKjn3ZvPmzdDpdBg3bpx4dceHH34ojru4uCArKwvR0dEICAhA9+7dER8fL/muoSeffBLp6elYtGgR3nrrLfTt2xc7duyQXFq7YMECVFRUYO7cuSgvL8fTTz+NzMxMq/xGWiIiImp5zQ5CY8aMgSA0fCfk3bvvfU8cNzc3pKenN1ozZMgQfPfdd43WTJ06FVOnTm1w3MbGBkuWLJFcFktERERUq9XPESIiIiJqrxiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhItjq1dQNERNT+9VqY0eDYuffCHmInRC2L7wgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsNTsI7d27F88++yy8vLxgY2ODHTt2SMYFQUB8fDw8PT3h6OiI4OBg/PTTT5Kay5cvY+bMmVCpVHB1dUVkZCSuX78uqTl27BieeeYZODg4wNvbG8nJyXV62bZtG/r37w8HBwcMHjwYu3btanYvREREJF/NDkIVFRUYOnQoUlJS6h1PTk7Ghx9+iNTUVOTn56Nz587QarW4deuWWDNz5kwUFxfDYDBg586d2Lt3L+bOnSuOm81mhISEwMfHBwUFBXj//feRkJCAjz/+WKzZv38/ZsyYgcjISBw9ehSTJ0/G5MmTcfz48Wb1QkRERPLVqbkrhIaGIjQ0tN4xQRCwatUqLFq0CJMmTQIAfPbZZ/Dw8MCOHTswffp0nDx5EpmZmTh06BBGjBgBAFizZg0mTpyIDz74AF5eXti8eTMqKyuxYcMGKBQKDBw4EIWFhVixYoUYmFavXo0JEyZg/vz5AIClS5fCYDBg7dq1SE1NbVIvv2axWGCxWMTHZrMZAFBVVYWqqqoG90ntmNJWaHTcGtT2ak09N4RzaZ860lyIyPo1Owg15uzZszCZTAgODhaXubi4IDAwEEajEdOnT4fRaISrq6sYggAgODgYtra2yM/Px3PPPQej0YjRo0dDoVCINVqtFsuWLcOVK1fQtWtXGI1G6PV6yfNrtVrxo7qm9PJrSUlJSExMrLM8KysLTk5O95z/0hE19S7/9Ud21sBgMLR1Cy2Gc2mfcnJy2roFIqKWDUImkwkA4OHhIVnu4eEhjplMJri7u0ub6NQJbm5ukhpfX98626gd69q1K0wm0z2f5169/FpcXJwkXJnNZnh7eyMkJAQqlarBeVdVVcFgMODtw7aw1NjUGT+eoG1w3famdi7jx4+Hvb19W7fzQDiX9ql2LkFBQW3dChFRywYha6dUKqFUKusst7e3b9KLj6XGBpbqukHIGl+4mjpna8C5tE8dZR5EZN1a9PJ5tVoNACgtLZUsLy0tFcfUajXKysok47dv38bly5clNfVt4+7naKjm7vF79UJERETy1qJByNfXF2q1GtnZ2eIys9mM/Px8aDQaAIBGo0F5eTkKCgrEmj179qCmpgaBgYFizd69eyUnUxoMBvTr1w9du3YVa+5+ntqa2udpSi9EREQkb80OQtevX0dhYSEKCwsB3DkpubCwECUlJbCxsUFMTAzeeecdfP311ygqKsJLL70ELy8vTJ48GQAwYMAATJgwAXPmzMHBgwfx/fffQ6fTYfr06fDy8gIAvPDCC1AoFIiMjERxcTG2bNmC1atXS87fef3115GZmYnly5fj1KlTSEhIwOHDh6HT6QCgSb0QERGRvDX7HKHDhw9LTnKsDScRERFIS0vDggULUFFRgblz56K8vBxPP/00MjMz4eDgIK6zefNm6HQ6jBs3Dra2tggPD8eHH34ojru4uCArKwvR0dEICAhA9+7dER8fL/muoSeffBLp6elYtGgR3nrrLfTt2xc7duzAoEGDxJqm9EJERETy1ewgNGbMGAhC/d+XA9x5J2bJkiVYsmRJgzVubm5IT09v9HmGDBmC7777rtGaqVOnYurUqQ/UCxEREckX7zVGREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBERFYjKSkJTzzxBLp06QJ3d3dMnjwZp0+fltTcunUL0dHR6NatG5ydnREeHo7S0lJJTUlJCcLCwuDk5AR3d3fMnz8ft2/fltTk5uZi+PDhUCqV6NOnD9LS0ur0k5KSgl69esHBwQGBgYE4ePBgi8+ZiFoXgxARWY28vDxER0fjwIEDMBgMqKqqQkhICCoqKsSa2NhYfPPNN9i2bRvy8vJw/vx5TJkyRRyvrq5GWFgYKisrsX//fmzatAlpaWmIj48Xa86ePYuwsDAEBQWhsLAQMTExeOWVV7B7926xZsuWLdDr9Vi8eDGOHDmCoUOHQqvVoqys7OHsDCJqEZ3augEioqbKzMyUPE5LS4O7uzsKCgowevRoXL16FZ9++inS09MxduxYAMDGjRsxYMAAHDhwAKNGjUJWVhZOnDiBb7/9Fh4eHvD398fSpUvx5ptvIiEhAQqFAqmpqfD19cXy5csBAAMGDMC+ffuwcuVKaLVaAMCKFSswZ84czJ49GwCQmpqKjIwMbNiwAQsXLqy3f4vFAovFIj42m80AgKqqKsl/f01pJ9zvLnsoGuq7NZ7jYTyXNeL+kWrOfmAQIiKrdfXqVQCAm5sbAKCgoABVVVUIDg4Wa/r374+ePXvCaDRi1KhRMBqNGDx4MDw8PMQarVaLqKgoFBcXY9iwYTAajZJt1NbExMQAACorK1FQUIC4uDhx3NbWFsHBwTAajQ32m5SUhMTExDrLc3Jy4OTkBIPBUO96ySPvsSPa2K5dux7aczW0j+gO7p87bty40eRaBiEisko1NTWIiYnBU089hUGDBgEATCYTFAoFXF1dJbUeHh4wmUxizd0hqHa8dqyxGrPZjJs3b+LKlSuorq6ut+bUqVMN9hwXFwe9Xi8+NpvN8Pb2RlBQEPLz8zF+/HjY29vXWW9Qwu46y9qT4wnaVn+OqqoqGAyGBveR3HH/SNW+29oUDEJEZJWio6Nx/Phx7Nu3r61baTKlUgmlUllnee0Ll729fb0vYpZqm1bv7UH0fTur3uXn3gtr8edqaB/RHdw/dzRnH/BkaSKyOjqdDjt37kROTg569OghLler1aisrER5ebmkvrS0FGq1Wqz59VVktY/vVaNSqeDo6Iju3bvDzs6u3prabRCRdWAQIiKrIQgCdDodtm/fjj179sDX11cyHhAQAHt7e2RnZ4vLTp8+jZKSEmg0GgCARqNBUVGR5Ooug8EAlUoFPz8/sebubdTW1G5DoVAgICBAUlNTU4Ps7GyxhoisAz8aIyKrER0djfT0dPztb39Dly5dxHN6XFxc4OjoCBcXF0RGRkKv18PNzQ0qlQqvvfYaNBoNRo0aBQAICQmBn58fXnzxRSQnJ8NkMmHRokWIjo4WP7aaN28e1q5diwULFuDll1/Gnj17sHXrVmRkZIi96PV6REREYMSIERg5ciRWrVqFiooK8SoyIrIODEJEZDXWr18PABgzZoxk+caNGzFr1iwAwMqVK2Fra4vw8HBYLBZotVqsW7dOrLWzs8POnTsRFRUFjUaDzp07IyIiAkuWLBFrfH19kZGRgdjYWKxevRo9evTAJ598Il46DwDTpk3DxYsXER8fD5PJBH9/f2RmZtY5gZqI2jcGISKyGoJw7+/TcXBwQEpKClJSUhqs8fHxuecl32PGjMHRo0cbrdHpdNDpdPfsiYjaL54jRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESy1eJBKCEhATY2NpKf/v37i+O3bt1CdHQ0unXrBmdnZ4SHh6O0tFSyjZKSEoSFhcHJyQnu7u6YP38+bt++LanJzc3F8OHDoVQq0adPH6SlpdXpJSUlBb169YKDgwMCAwNx8ODBlp4uERERWbFWeUdo4MCBuHDhgvizb98+cSw2NhbffPMNtm3bhry8PJw/fx5TpkwRx6urqxEWFobKykrs378fmzZtQlpaGuLj48Was2fPIiwsDEFBQSgsLERMTAxeeeUV7N69W6zZsmUL9Ho9Fi9ejCNHjmDo0KHQarUoKytrjSkTERGRFWqVINSpUyeo1Wrxp3v37gCAq1ev4tNPP8WKFSswduxYBAQEYOPGjdi/fz8OHDgAAMjKysKJEyfw+eefw9/fH6GhoVi6dClSUlJQWVkJAEhNTYWvry+WL1+OAQMGQKfT4fnnn8fKlSvFHlasWIE5c+Zg9uzZ8PPzQ2pqKpycnLBhw4bWmDIRERFZoU6tsdGffvoJXl5ecHBwgEajQVJSEnr27ImCggJUVVUhODhYrO3fvz969uwJo9GIUaNGwWg0YvDgwfDw8BBrtFotoqKiUFxcjGHDhsFoNEq2UVsTExMDAKisrERBQQHi4uLEcVtbWwQHB8NoNDbYt8VigcViER+bzWYAQFVVFaqqqhpcr3ZMaSs0Om4Nanu1pp4bwrm0Tx1pLkRk/Vo8CAUGBiItLQ39+vXDhQsXkJiYiGeeeQbHjx+HyWSCQqGAq6urZB0PDw+YTCYAgMlkkoSg2vHascZqzGYzbt68iStXrqC6urremlOnTjXYe1JSEhITE+ssz8rKgpOT0z3nvnRETb3Ld+3adc912xuDwdDWLbQYzqV9ysnJaesWqJX1WpjR4Ni598IeYidEDWvxIBQaGir+/5AhQxAYGAgfHx9s3boVjo6OLf10LSouLg56vV58bDab4e3tjZCQEKhUqgbXq6qqgsFgwNuHbWGpsakzfjxB2yr9tobauYwfPx729vZt3c4D4Vzap9q5BAUFtXUrRESt89HY3VxdXfH444/j559/xvjx41FZWYny8nLJu0KlpaVQq9UAALVaXefqrtqryu6u+fWVZqWlpVCpVHB0dISdnR3s7OzqrandRn2USiWUSmWd5fb29k168bHU2MBSXTcIWeMLV1PnbA04l/apo8yDiKxbq3+P0PXr13HmzBl4enoiICAA9vb2yM7OFsdPnz6NkpISaDQaAIBGo0FRUZHk6i6DwQCVSgU/Pz+x5u5t1NbUbkOhUCAgIEBSU1NTg+zsbLGGiIiIqMWD0BtvvIG8vDycO3cO+/fvx3PPPQc7OzvMmDEDLi4uiIyMhF6vR05ODgoKCjB79mxoNBqMGjUKABASEgI/Pz+8+OKL+OGHH7B7924sWrQI0dHR4rs18+bNwz/+8Q8sWLAAp06dwrp167B161bExsaKfej1evz5z3/Gpk2bcPLkSURFRaGiogKzZ89u6SkTERGRlWrxj8b+9a9/YcaMGbh06RIeeeQRPP300zhw4AAeeeQRAMDKlStha2uL8PBwWCwWaLVarFu3Tlzfzs4OO3fuRFRUFDQaDTp37oyIiAgsWbJErPH19UVGRgZiY2OxevVq9OjRA5988gm02v+eizNt2jRcvHgR8fHxMJlM8Pf3R2ZmZp0TqImIiEi+WjwIffHFF42OOzg4ICUlBSkpKQ3W+Pj43PNKqzFjxuDo0aON1uh0Ouh0ukZriIiISL5a/WRpavgSUl4+SkRE1LZ401UiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki3ea4yIiB463oOR2gu+I0RERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssUgRERERLLFIERERESyxSBEREREssV7jRERkdUYlLAblmobyTLen4weBN8RIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZYhAiIiIi2WIQIiIiItliECIiIiLZ4hcqEhGRVeu1MKPBMX7ZIt0L3xEiIiIi2WIQIiIiItliECIiIiLZ4jlCbYifaxMREbUtBiEiIuqwGvoHJ/+xSbX40RgRERHJFoMQERERyZYsglBKSgp69eoFBwcHBAYG4uDBg23dEhF1EDy+WKdeCzMa/CF56fBBaMuWLdDr9Vi8eDGOHDmCoUOHQqvVoqysrK1bIyIrx+MLkfXr8CdLr1ixAnPmzMHs2bMBAKmpqcjIyMCGDRuwcOHCNu6uYTzBj6j9s9bjCzWOV/TKS4cOQpWVlSgoKEBcXJy4zNbWFsHBwTAajXXqLRYLLBaL+Pjq1asAgMuXL6OqqqrB56mqqsKNGzfQqcoW1TU2LTiDui5dutSq26+dy6VLl2Bvb9+qz9XaOJf2qXYuly9fBgAIgtDGHd2f5h5fgMaPMY39+Xa6XdHC3bdfDR3jHuZxtjF93tja7HXy48a1QidSHekY0RKuXbsGoGnHlw4dhP7zn/+guroaHh4ekuUeHh44depUnfqkpCQkJibWWe7r69tqPTZX9+Vt3QFRy7p27RpcXFzauo1ma+7xBWj4GPP444+3So/WqCMe4zrinKxFU44vHToINVdcXBz0er34uKamBpcvX0a3bt1gY9Pwv0DMZjO8vb3xyy+/QKVSPYxWWw3n0j51xLmUlJTAxsYGXl5ebd3SQ9PQMcbe3h49e/bsEH++raUj/Q60Bu4fKUEQcO3atSYdXzp0EOrevTvs7OxQWloqWV5aWgq1Wl2nXqlUQqlUSpa5uro2+flUKlWH+QvIubRPHWkuLi4uVj2X5h5fgIaPMWazGUDH+vNtLdxHjeP++a+mvtPcoa8aUygUCAgIQHZ2trispqYG2dnZ0Gg0bdgZEVk7Hl+IOoYO/Y4QAOj1ekRERGDEiBEYOXIkVq1ahYqKCvEqDyKi+8XjC5H16/BBaNq0abh48SLi4+NhMpng7++PzMzMOic4PgilUonFixfXecvbGnEu7RPn0j611PGlI+2T1sJ91Djun/tnI1jrtatERERED6hDnyNERERE1BgGISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBqEWkJKSgl69esHBwQGBgYE4ePBgW7ckkZCQABsbG8lP//79xfFbt24hOjoa3bp1g7OzM8LDw+t8W25JSQnCwsLg5OQEd3d3zJ8/H7dv32713vfu3Ytnn30WXl5esLGxwY4dOyTjgiAgPj4enp6ecHR0RHBwMH766SdJzeXLlzFz5kyoVCq4uroiMjIS169fl9QcO3YMzzzzDBwcHODt7Y3k5OSHPpdZs2bV+XOaMGFCu5xLUlISnnjiCXTp0gXu7u6YPHkyTp8+Lalpqb9Xubm5GD58OJRKJfr06YO0tLQWn09ba+/HkIepJX7nO7KW+t2juwj0QL744gtBoVAIGzZsEIqLi4U5c+YIrq6uQmlpaVu3Jlq8eLEwcOBA4cKFC+LPxYsXxfF58+YJ3t7eQnZ2tnD48GFh1KhRwpNPPimO3759Wxg0aJAQHBwsHD16VNi1a5fQvXt3IS4urtV737Vrl/B///d/wldffSUAELZv3y4Zf++99wQXFxdhx44dwg8//CD8z//8j+Dr6yvcvHlTrJkwYYIwdOhQ4cCBA8J3330n9OnTR5gxY4Y4fvXqVcHDw0OYOXOmcPz4ceEvf/mL4OjoKHz00UcPdS4RERHChAkTJH9Oly9fltS0l7lotVph48aNwvHjx4XCwkJh4sSJQs+ePYXr16+LNS3x9+of//iH4OTkJOj1euHEiRPCmjVrBDs7OyEzM7NF59OWrOEY8jC1xO98R9YSv3skxSD0gEaOHClER0eLj6urqwUvLy8hKSmpDbuSWrx4sTB06NB6x8rLywV7e3th27Zt4rKTJ08KAASj0SgIwp0Dk62trWAymcSa9evXCyqVSrBYLK3a+91+fVCsqakR1Gq18P7774vLysvLBaVSKfzlL38RBEEQTpw4IQAQDh06JNb8/e9/F2xsbIR///vfgiAIwrp164SuXbtK5vLmm28K/fr1e2hzEYQ7QWjSpEkNrtNe5yIIglBWViYAEPLy8gRBaLm/VwsWLBAGDhwoea5p06YJWq22VefzMFnDMaSt3M/vvNzcz+8eSfGjsQdQWVmJgoICBAcHi8tsbW0RHBwMo9HYhp3V9dNPP8HLywuPPfYYZs6ciZKSEgBAQUEBqqqqJHPo378/evbsKc7BaDRi8ODBkm/L1Wq1MJvNKC4ufrgTucvZs2dhMpkkvbu4uCAwMFDSu6urK0aMGCHWBAcHw9bWFvn5+WLN6NGjoVAoxBqtVovTp0/jypUrD2k2d+Tm5sLd3R39+vVDVFQULl26JI6157lcvXoVAODm5gag5f5eGY1GyTZqa9rb79f9sqZjSHvQlN95ubmf3z2SYhB6AP/5z39QXV1d5+v0PTw8YDKZ2qirugIDA5GWlobMzEysX78eZ8+exTPPPINr167BZDJBoVDA1dVVss7dczCZTPXOsXasrdQ+d2P732Qywd3dXTLeqVMnuLm5tbv5TZgwAZ999hmys7OxbNky5OXlITQ0FNXV1WIv7XEuNTU1iImJwVNPPYVBgwaJz9USf68aqjGbzbh582ZrTOehspZjSHvRlN95Obnf3z2S6vD3GiMgNDRU/P8hQ4YgMDAQPj4+2Lp1KxwdHduwM7rb9OnTxf8fPHgwhgwZgt69eyM3Nxfjxo1rw84aFx0djePHj2Pfvn1t3QqRrPB3r2XwHaEH0L17d9jZ2dU5G7+0tBRqtbqNuro3V1dXPP744/j555+hVqtRWVmJ8vJySc3dc1Cr1fXOsXasrdQ+d2P7X61Wo6ysTDJ++/ZtXL58ud3P77HHHkP37t3x888/i720t7nodDrs3LkTOTk56NGjh7i8pf5eNVSjUqk6RIi31mNIW2nK77xcPMjvHkkxCD0AhUKBgIAAZGdni8tqamqQnZ0NjUbThp017vr16zhz5gw8PT0REBAAe3t7yRxOnz6NkpIScQ4ajQZFRUWSF2GDwQCVSgU/P7+H3n8tX19fqNVqSe9msxn5+fmS3svLy1FQUCDW7NmzBzU1NQgMDBRr9u7di6qqKrHGYDCgX79+6Nq160OaTV3/+te/cOnSJXh6egJoX3MRBAE6nQ7bt2/Hnj174OvrKxlvqb9XGo1Gso3amvb8+9Uc1noMaStN+Z3v6Frid49+pa3P1rZ2X3zxhaBUKoW0tDThxIkTwty5cwVXV1fJlTBt7Y9//KOQm5srnD17Vvj++++F4OBgoXv37kJZWZkgCHcutezZs6ewZ88e4fDhw4JGoxE0Go24fu1lziEhIUJhYaGQmZkpPPLIIw/l8vlr164JR48eFY4ePSoAEFasWCEcPXpU+Oc//ykIwp1LaV1dXYW//e1vwrFjx4RJkybVe/n8sGHDhPz8fGHfvn1C3759JZecl5eXCx4eHsKLL74oHD9+XPjiiy8EJyenFr/kvLG5XLt2TXjjjTcEo9EonD17Vvj222+F4cOHC3379hVu3brV7uYSFRUluLi4CLm5uZLL/W/cuCHWtMTfq9rL5+fPny+cPHlSSElJ6ZCXz7f3Y8jD1BK/8x1ZS/zukRSDUAtYs2aN0LNnT0GhUAgjR44UDhw40NYtSUybNk3w9PQUFAqF8OijjwrTpk0Tfv75Z3H85s2bwquvvip07dpVcHJyEp577jnhwoULkm2cO3dOCA0NFRwdHYXu3bsLf/zjH4WqqqpW7z0nJ0cAUOcnIiJCEIQ7l9O+/fbbgoeHh6BUKoVx48YJp0+flmzj0qVLwowZMwRnZ2dBpVIJs2fPFq5duyap+eGHH4Snn35aUCqVwqOPPiq89957D3UuN27cEEJCQoRHHnlEsLe3F3x8fIQ5c+bUeTFsL3Opbx4AhI0bN4o1LfX3KicnR/D39xcUCoXw2GOPSZ6jo2jvx5CHqSV+5zuylvrdo/+yEQRBeBjvPBERERG1NzxHiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhk6/8DqQKDw4/pLZ8AAAAASUVORK5CYII=","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","text_word_count = []\n","summary_word_count = []\n","\n","# populate the lists with sentence lengths\n","for i in data['cleaned_text']:\n","      text_word_count.append(len(i.split()))\n","\n","for i in data['cleaned_summary']:\n","      summary_word_count.append(len(i.split()))\n","\n","length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n","\n","length_df.hist(bins = 30)\n","plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"7JRjwdIOFxg3","outputId":"f968be82-c539-471d-ce23-16f18b059ea0","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.980140281988159\n"]}],"source":["cnt=0\n","for i in data['cleaned_summary']:\n","    if(len(i.split())<=10):\n","        cnt=cnt+1\n","print(cnt/len(data['cleaned_summary']))"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9130307623446116\n"]}],"source":["cnt=0\n","for i in data['cleaned_text']:\n","    if(len(i.split())<=80):\n","        cnt=cnt+1\n","print(cnt/len(data['cleaned_text']))"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"ZKD5VOWqFxhC","trusted":true},"outputs":[],"source":["max_text_len=80\n","max_summary_len=10"]},{"cell_type":"markdown","metadata":{},"source":["## **Handling Outliers**\n","\n","In this step, we focus on identifying and removing outliers from the dataset. Outliers are data points that deviate significantly from the typical range and can negatively impact model performance. We use techniques like box plots, z-scores, and the interquartile range (IQR) to detect and eliminate outliers.\n","\n","Benefits:\n","- Improved model performance\n","- Enhanced data consistency\n","- Accurate statistical analysis\n","- Clearer data interpretation\n","\n","Eliminating outliers ensures data quality and prepares it for text summarization.\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"yY0tEJP0FxhI","trusted":true},"outputs":[],"source":["cleaned_text =np.array(data['cleaned_text'])\n","cleaned_summary=np.array(data['cleaned_summary'])\n","\n","short_text=[]\n","short_summary=[]\n","\n","for i in range(len(cleaned_text)):\n","    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n","        short_text.append(cleaned_text[i])\n","        short_summary.append(cleaned_summary[i])\n","        \n","df=pd.DataFrame({'text':short_text,'summary':short_summary})"]},{"cell_type":"markdown","metadata":{},"source":["## **Adding Start and End Tokens to Summaries**\n","\n","In this step, we prepend a start token (`<start>`) and append an end token (`<end>`) to each summary in the dataset. These tokens play a crucial role in sequence-to-sequence models for text summarization. The start token signifies the beginning of the summary, while the end token indicates the summary's conclusion.\n","\n","Benefits:\n","- Improved model understanding of summary boundaries\n","- Enhanced text generation quality\n","- Proper sequence initialization\n","\n","Adding start and end tokens is a fundamental preprocessing step for sequence-to-sequence models.\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"EwLUH78CFxhg","trusted":true},"outputs":[],"source":["df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Review: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n","Summary: sostok good quality dog food eostok\n","\n","\n","Review: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n","Summary: sostok not as advertised eostok\n","\n","\n","Review: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n","Summary: sostok delight says it all eostok\n","\n","\n","Review: looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n","Summary: sostok cough medicine eostok\n","\n","\n","Review: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n","Summary: sostok great taffy eostok\n","\n","\n"]}],"source":["for i in range(5):\n","    print(\"Review:\",df['text'][i])\n","    print(\"Summary:\",df['summary'][i])\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["## **Splitting Training and Test Sets**\n","\n","This step involves splitting the dataset into two distinct subsets: a training set and a test set. The training set will be used to train your machine learning model, while the test set will be reserved for evaluating the model's performance.\n","\n","Key Aspects:\n","- Randomized selection to ensure representativeness\n","- Common split ratios: e.g., 80% for training, 20% for testing\n","- Evaluation performed on unseen data for robustness assessment\n","\n","Careful selection of training and test data is crucial for model training and evaluation, ensuring reliable results and effective learning.\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"RakakKHcFxhl","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.05,random_state=0,shuffle=True) "]},{"cell_type":"markdown","metadata":{},"source":["The decision to utilize Long Short-Term Memory (LSTM) networks within our encoder-decoder architecture is a strategic one for our text summarization model. LSTMs have been chosen for their exceptional ability to capture sequential dependencies and long-range associations within textual data. \n","\n","In the encoder phase, LSTMs excel at effectively encoding the input text, enabling the model to comprehend the intricate structure and context of the content. Simultaneously, during the decoder phase, they play a pivotal role in facilitating the generation of summaries by ensuring the preservation of relevant information and its contextual communication.\n","\n","This LSTM-based encoder-decoder framework empowers our model to extract salient information from the input, maintain fluency and coherence, and generate concise and contextually accurate summaries. It stands as a robust and versatile solution for addressing the challenges of text summarization tasks. In summary, LSTMs within the encoder-decoder architecture are pivotal in achieving the model's proficiency in text summarization.\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Creating a Tokenizer for Training Reviews**\n","\n","In this step, a tokenizer is created specifically for the training reviews. A tokenizer is an essential tool for text preprocessing, as it breaks down the text into individual words or tokens. This process is crucial for converting text data into a format that can be utilized by machine learning models.\n","\n","Key Aspects:\n","- Tokenization helps to represent text data numerically.\n","- It facilitates vocabulary creation for the model.\n","- Training-specific tokenizer ensures consistency with the training data.\n","\n","The tokenizer is a fundamental component of natural language processing (NLP) tasks and contributes to model training and text data handling.\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"oRHTgX6hFxhq","trusted":true},"outputs":[],"source":["x_tokenizer = Tokenizer() \n","x_tokenizer.fit_on_texts(list(x_tr))"]},{"cell_type":"markdown","metadata":{},"source":["## **Analyzing Word Frequency in Reviews**\n","\n","This step involves an analysis of word frequency within the reviews. Two key categories are considered: rare and common words.\n","\n","Key Aspects:\n","- **Rare Words:** Words with low occurrence in the dataset.\n","- **Common Words:** Frequently occurring words that are essential for understanding the text.\n","\n","Understanding word frequency is crucial for effective text processing and modeling. It helps identify unique and recurring vocabulary within the reviews.\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"y8KronV2Fxhx","outputId":"d2eb2f27-fbbc-4e61-9556-3c3ff5e4327b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["% of rare words in vocabulary: 67.99448802204792\n","Total Coverage of rare words: 0.8633340536872359\n"]}],"source":["thresh=4\n","\n","cnt=0\n","tot_cnt=0\n","freq=0\n","tot_freq=0\n","\n","for key,value in x_tokenizer.word_counts.items():\n","    tot_cnt=tot_cnt+1\n","    tot_freq=tot_freq+value\n","    if(value<thresh):\n","        cnt=cnt+1\n","        freq=freq+value\n","    \n","print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n","print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"]},{"cell_type":"markdown","metadata":{},"source":["## **Creating Review Tokenizer with Common Words**\n","\n","In this step, a tokenizer is established for the reviews, primarily focusing on the most common words. Tokenization is a crucial text preprocessing technique, and by prioritizing common words, we ensure that the tokenizer captures essential language patterns for further analysis and modeling.\n","\n","This tokenizer forms the foundation for transforming reviews into numerical data that machine learning models can process effectively.\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"J2giEsF3Fxh3","trusted":true},"outputs":[],"source":["#prepare a tokenizer for reviews on training data\n","x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n","x_tokenizer.fit_on_texts(list(x_tr))\n","\n","#convert text sequences into integer sequences\n","x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n","x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n","\n","#padding zero upto maximum length\n","x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n","x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n","\n","#size of vocabulary ( +1 for padding token)\n","x_voc   =  x_tokenizer.num_words + 1"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"DCbGMsm4FxiA","outputId":"2d9165f0-e542-4114-91f3-e070d483fce9","trusted":true},"outputs":[{"data":{"text/plain":["30195"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["x_voc"]},{"cell_type":"markdown","metadata":{},"source":["## **Creating Summary Tokenizer from Training Data**\n","\n","This step involves the creation of a tokenizer specifically designed for the summaries extracted from the training data. Tokenization of summaries is essential for transforming them into a format suitable for machine learning models.\n","\n","By building a summary tokenizer from the training data, we ensure that it aligns with the linguistic characteristics of our specific dataset, improving the quality of text-to-numbers conversion. This tokenizer is a key component for subsequent text summarization tasks.\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"eRHqyBkBFxiJ","trusted":true},"outputs":[],"source":["y_tokenizer = Tokenizer()\n","y_tokenizer.fit_on_texts(list(y_tr))"]},{"cell_type":"markdown","metadata":{},"source":["## **Analyzing Summary Vocabulary: Common and Rare Words**\n","\n","In this step, we perform a vocabulary analysis on the summaries extracted from the dataset. The analysis involves identifying both common words, which occur frequently, and rare words, which have limited occurrences in the summaries.\n","\n","Understanding the distribution of words in the summaries is crucial for optimizing the text summarization process. It allows us to determine which words are prevalent and which may require special handling. This knowledge contributes to the efficiency and quality of our summarization model.\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"yzE5OiRLFxiM","outputId":"7f7a4f89-b088-4847-8172-09e5a2383d0e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["% of rare words in vocabulary: 74.62345486652124\n","Total Coverage of rare words: 1.869156915502513\n"]}],"source":["thresh=6\n","\n","cnt=0\n","tot_cnt=0\n","freq=0\n","tot_freq=0\n","\n","for key,value in y_tokenizer.word_counts.items():\n","    tot_cnt=tot_cnt+1\n","    tot_freq=tot_freq+value\n","    if(value<thresh):\n","        cnt=cnt+1\n","        freq=freq+value\n","    \n","print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n","print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"]},{"cell_type":"markdown","metadata":{},"source":["## **Summary Tokenization: Extracting Common Words**\n","\n","In this step, we define a tokenizer specifically designed to extract the most common words from the summaries within the training dataset. This tokenizer enables us to identify and process frequently occurring words, which are essential for building a robust and effective text summarization model.\n","\n","By focusing on the most common words, we streamline the summarization process and improve the model's ability to capture the key content of the input text. This optimization contributes to the overall quality and accuracy of our summarization system.\n"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"-fswLvIgFxiR","trusted":true},"outputs":[],"source":["#prepare a tokenizer for summaries on training data\n","y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n","y_tokenizer.fit_on_texts(list(y_tr))\n","\n","#convert text sequences into integer sequences\n","y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n","y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n","\n","#padding zero upto maximum length\n","y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n","y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n","\n","#size of vocabulary\n","y_voc  =   y_tokenizer.num_words +1"]},{"cell_type":"markdown","metadata":{},"source":["## **Validating Start Token Length**\n","\n","In this step, we ensure the consistency of the start token's length by comparing it to the total length of the training data. The start token plays a critical role in the text summarization process, and its length should align with the structure of our dataset.\n","\n","By verifying that the start token length matches the dataset's size, we maintain data integrity and establish a fundamental component for our summarization model. This validation is essential to avoid unexpected issues during the model's training and inference phases.\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"pR8IX9FRFxiY","outputId":"b116cdbd-42c4-4ede-9f6d-46284115393e","trusted":true},"outputs":[{"data":{"text/plain":["(335878, 335878)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["y_tokenizer.word_counts['sostok'],len(y_tr)"]},{"cell_type":"markdown","metadata":{},"source":["## **Eliminating Rows with Only Start and End Tokens**\n","\n","In this step, we identify and remove rows from our dataset that solely consist of START and END tokens. These tokens are crucial for defining the beginning and end of a summary but don't contribute meaningful content on their own.\n","\n","By eliminating such rows, we enhance the quality of our dataset for training and testing. This process ensures that the summarization model focuses on actual reviews and summaries while excluding rows with no substantial information. It's an essential data preprocessing step for improved model performance.\n"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"kZ-vW82sFxih","trusted":true},"outputs":[],"source":["ind=[]\n","for i in range(len(y_tr)):\n","    cnt=0\n","    for j in y_tr[i]:\n","        if j!=0:\n","            cnt=cnt+1\n","    if(cnt==2):\n","        ind.append(i)\n","\n","y_tr=np.delete(y_tr,ind, axis=0)\n","x_tr=np.delete(x_tr,ind, axis=0)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"cx5NISuMFxik","trusted":true},"outputs":[],"source":["ind=[]\n","for i in range(len(y_val)):\n","    cnt=0\n","    for j in y_val[i]:\n","        if j!=0:\n","            cnt=cnt+1\n","    if(cnt==2):\n","        ind.append(i)\n","\n","y_val=np.delete(y_val,ind, axis=0)\n","x_val=np.delete(x_val,ind, axis=0)"]},{"cell_type":"markdown","metadata":{},"source":["## **Model Building: Defining LSTM Layers, Encoder, and Decoder**\n","\n","In this section, we establish the architecture of our text summarization model. This model leverages LSTM (Long Short-Term Memory) layers to understand and generate meaningful summaries from input reviews. The process involves two main components: the Encoder and the Decoder.\n","\n","- **Encoder**: The Encoder is responsible for comprehending the input reviews. We use LSTM layers within the Encoder to capture the sequential information within the reviews effectively. This allows the model to create a context for generating summaries.\n","\n","- **Decoder**: The Decoder is tasked with generating the output summaries. It also utilizes LSTM layers and attention mechanisms to ensure that the generated summaries are contextually accurate and coherent.\n","\n","By defining these components and connecting them properly, we create a powerful text summarization model that can process and summarize reviews intelligently. This model's architecture plays a pivotal role in delivering meaningful and relevant summaries for the given input data.\n"]},{"cell_type":"code","execution_count":38,"metadata":{"_kg_hide-output":false,"id":"zXef38nBFxir","outputId":"7ae99521-46f8-4c6f-9cba-4979deffeee8","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 80)]                 0         []                            \n","                                                                                                  \n"," embedding (Embedding)       (None, 80, 100)              3019500   ['input_1[0][0]']             \n","                                                                                                  \n"," lstm (LSTM)                 [(None, 80, 300),            481200    ['embedding[0][0]']           \n","                              (None, 300),                                                        \n","                              (None, 300)]                                                        \n","                                                                                                  \n"," input_2 (InputLayer)        [(None, None)]               0         []                            \n","                                                                                                  \n"," lstm_1 (LSTM)               [(None, 80, 300),            721200    ['lstm[0][0]']                \n","                              (None, 300),                                                        \n","                              (None, 300)]                                                        \n","                                                                                                  \n"," embedding_1 (Embedding)     (None, None, 100)            733000    ['input_2[0][0]']             \n","                                                                                                  \n"," lstm_2 (LSTM)               [(None, 80, 300),            721200    ['lstm_1[0][0]']              \n","                              (None, 300),                                                        \n","                              (None, 300)]                                                        \n","                                                                                                  \n"," lstm_3 (LSTM)               [(None, None, 300),          481200    ['embedding_1[0][0]',         \n","                              (None, 300),                           'lstm_2[0][1]',              \n","                              (None, 300)]                           'lstm_2[0][2]']              \n","                                                                                                  \n"," attention_layer (Attention  ((None, None, 300),          180300    ['lstm_2[0][0]',              \n"," Layer)                       (None, None, 80))                      'lstm_3[0][0]']              \n","                                                                                                  \n"," concat_layer (Concatenate)  (None, None, 600)            0         ['lstm_3[0][0]',              \n","                                                                     'attention_layer[0][0]']     \n","                                                                                                  \n"," time_distributed (TimeDist  (None, None, 7330)           4405330   ['concat_layer[0][0]']        \n"," ributed)                                                                                         \n","                                                                                                  \n","==================================================================================================\n","Total params: 10742930 (40.98 MB)\n","Trainable params: 10742930 (40.98 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["from keras import backend as K \n","K.clear_session()\n","\n","latent_dim = 300\n","embedding_dim=100\n","\n","# Encoder\n","encoder_inputs = Input(shape=(max_text_len,))\n","\n","#embedding layer\n","enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n","\n","#encoder lstm 1\n","encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n","encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n","\n","#encoder lstm 2\n","encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n","encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n","\n","#encoder lstm 3\n","encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n","encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None,))\n","\n","#embedding layer\n","dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n","dec_emb = dec_emb_layer(decoder_inputs)\n","\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n","decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n","\n","# Attention layer\n","attn_layer = AttentionLayer(name='attention_layer')\n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","\n","# Concat attention input and decoder LSTM output\n","decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n","\n","#dense layer\n","decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n","decoder_outputs = decoder_dense(decoder_concat_input)\n","\n","\n","# Define the model \n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.summary() "]},{"cell_type":"code","execution_count":39,"metadata":{"id":"Lwfi1Fm8Fxiz","trusted":true},"outputs":[],"source":["model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"]},{"cell_type":"markdown","metadata":{},"source":["## **Monitoring Validation Loss**\n","\n","To ensure the effectiveness of our text summarization model and prevent overfitting, we continuously monitor the validation loss during the training process. Validation loss serves as an essential metric for assessing the model's performance on data it hasn't seen during training.\n","\n","- **Purpose**: The primary purpose of monitoring the validation loss is to gauge how well the model generalizes to unseen data. If the validation loss starts to increase while the training loss decreases, it's an indicator that the model may be overfitting, and adjustments are needed.\n","\n","- **Early Stopping**: We employ an early stopping mechanism based on the validation loss. If the validation loss doesn't show improvement over a certain number of epochs, the training process is halted to prevent further overfitting.\n","\n","- **Optimizing Model Parameters**: By observing the validation loss, we can fine-tune hyperparameters, adjust model architecture, or modify the training process to enhance the model's performance.\n","\n","Continuous validation loss monitoring is a crucial part of the training process, ensuring that our text summarization model is both accurate and capable of generalizing well to new data.\n"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"s-A3J92MUljB","trusted":true},"outputs":[],"source":["es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2), \n","      ModelCheckpoint('./MyModel_tf',monitor='val_loss', verbose=1,\n","                      save_best_only=True, mode='min', save_weights_only = False)]"]},{"cell_type":"markdown","metadata":{},"source":["## **Training the Model with Batch Size of 512 and 10% Validation**\n","\n","To train our text summarization model, we employ a batch size of 512 and implement a validation strategy using a 10% subset of the dataset. This approach helps ensure the model's robustness and generalization while efficiently utilizing computational resources.\n","\n","- **Batch Size**: We use a batch size of 512 for training. This means that, during each training iteration, the model processes 512 examples simultaneously. Larger batch sizes can lead to faster convergence but might require more memory.\n","\n","- **Validation Strategy**: To evaluate the model's performance during training, we set aside a 10% subset of the dataset for validation. This validation set remains unseen during training and serves as a benchmark for model performance.\n","\n","- **Early Stopping**: We continuously monitor the validation loss to implement an early stopping mechanism. If the validation loss stops improving or starts increasing, the training process is halted to prevent overfitting.\n","\n","- **Hyperparameter Tuning**: The choice of batch size and the size of the validation subset are hyperparameters that can be fine-tuned to optimize the model's performance. This process helps strike a balance between efficiency and model accuracy.\n","\n","Training with an appropriate batch size and validation strategy is a crucial step in developing a reliable and accurate text summarization model.\n"]},{"cell_type":"code","execution_count":64,"metadata":{"_kg_hide-output":false,"id":"ETnPzA4OFxi3","outputId":"477e374f-7cf2-4d60-f86e-2c49c9cebedb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"," 32/650 [>.............................] - ETA: 6:39:57 - loss: 3.2704"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32md:\\Internet_Downloads\\Programming_Languages\\Programs\\Text_Summarization\\src\\text-summarization-using-lstm.ipynb Cell 62\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit([x_tr,y_tr[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]], y_tr\u001b[39m.\u001b[39;49mreshape(y_tr\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m],y_tr\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)[:,\u001b[39m1\u001b[39;49m:] ,epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[es],batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m([x_val,y_val[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]], y_val\u001b[39m.\u001b[39;49mreshape(y_val\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m],y_val\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)[:,\u001b[39m1\u001b[39;49m:]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y115sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# from kaggle.api.kaggle_api_extended import KaggleApi\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y115sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y115sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# # Authenticate with Kaggle server\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y115sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# api = KaggleApi()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y115sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# api.authenticate()\u001b[39;00m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=3,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n","# from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","# # Authenticate with Kaggle server\n","# api = KaggleApi()\n","# api.authenticate()"]},{"cell_type":"code","execution_count":65,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved model to disk\n"]}],"source":["# serialize model to JSON\n","model_json = model.to_json()\n","with open(\"summary.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"summary.h5\")\n","print(\"Saved model to disk\")"]},{"cell_type":"markdown","metadata":{},"source":["## **Analyzing Model Behavior Over Time**\n","\n","In our text summarization project, it's essential to gain insights into how the model behaves and evolves throughout the training process. This understanding aids in assessing its learning dynamics and identifying potential areas for improvement.\n","\n","Key points to consider for analyzing the model's behavior over time include:\n","\n","- **Loss Curve**: We closely monitor the loss curve, which represents the model's training and validation loss over epochs. A decreasing training loss indicates that the model is learning and converging. Simultaneously, we assess the validation loss, which helps detect overfitting or underfitting. The loss curve provides insights into whether the model is improving or plateauing over time.\n","\n","- **Learning Rate Schedule**: We might implement a learning rate schedule, such as learning rate decay, to adapt the learning rate during training. This schedule can influence how quickly or slowly the model converges, affecting its behavior over time.\n","\n","- **Epoch Analysis**: We analyze the model's performance at different epochs. This analysis can reveal trends, such as early rapid improvements or convergence to a stable state. It helps us decide when to stop training (early stopping) and whether further training is beneficial.\n","\n","- **Metrics and Evaluation**: We use various evaluation metrics, such as ROUGE scores for text summarization, to quantitatively assess the quality of generated summaries. Tracking these metrics over time provides insights into how well the model is performing on the task.\n","\n","- **Visualizations**: Visual aids like loss curves, learning rate schedules, and metric plots can provide a clear picture of the model's behavior. These visualizations facilitate decision-making regarding model adjustments or hyperparameter tuning.\n","\n","Understanding the model's behavior over time is a crucial step in the iterative process of model development. It allows us to make informed decisions, optimize training strategies, and ultimately achieve the best possible text summarization results.\n"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"tDTNLAURFxjE","outputId":"e2ea6e44-3931-4014-97a1-03fa2a441228","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32md:\\Internet_Downloads\\Programming_Languages\\Programs\\Text_Summarization\\src\\text-summarization-using-lstm.ipynb Cell 65\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y121sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pyplot\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y121sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pyplot\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Internet_Downloads/Programming_Languages/Programs/Text_Summarization/src/text-summarization-using-lstm.ipynb#Y121sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pyplot\u001b[39m.\u001b[39mlegend()\n","\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"]}],"source":["from matplotlib import pyplot\n","pyplot.plot(history.history['loss'], label='train')\n","pyplot.plot(history.history['val_loss'], label='test')\n","pyplot.legend()\n","pyplot.show()"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"sBX0zZnOFxjW","trusted":true},"outputs":[],"source":["reverse_target_word_index=y_tokenizer.index_word\n","reverse_source_word_index=x_tokenizer.index_word\n","target_word_index=y_tokenizer.word_index"]},{"cell_type":"markdown","metadata":{},"source":["## **Setting Up Inference for the Encoder and Decoder**\n","\n","In the context of text summarization, we need a way to utilize our trained model for generating summaries from input reviews. This is where inference comes into play. Inference allows us to apply our trained model in a way that facilitates automatic summarization.\n","\n","The following steps outline the process of setting up inference:\n","\n","1. **Inference Encoder**: We prepare the encoder part of our model for inference. This includes configuring the same layers and architecture as used during training. However, during inference, we load the trained weights into the encoder without backpropagation. This step ensures that the encoder processes the input reviews consistently and effectively.\n","\n","2. **Inference Decoder**: Similar to the encoder, we set up the decoder for inference. The decoder architecture remains the same as in training, but with the loaded trained weights. In this phase, we prepare the decoder for autoregressive summary generation.\n","\n","3. **Generating Summaries**: With the inference encoder and decoder ready, we can feed input reviews into the encoder to obtain the initial state. Then, using the initial state, we generate the summary one word at a time. This autoregressive process continues until an end token is predicted, indicating the completion of the summary.\n","\n","By setting up inference for the encoder and decoder, we can efficiently generate text summaries from input reviews, making our text summarization system a valuable tool for automating the summarization of large volumes of text data.\n","\n","This crucial step ensures that our trained model can be used for practical applications and provides a smooth transition from training to real-world use.\n"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"9QkrNV-4Fxjt","trusted":true},"outputs":[],"source":["# Encode the input sequence to get the feature vector\n","encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n","\n","# Decoder setup\n","# Below tensors will hold the states of the previous time step\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n","\n","# Get the embeddings of the decoder sequence\n","dec_emb2= dec_emb_layer(decoder_inputs) \n","# To predict the next word in the sequence, set the initial states to the states from the previous time step\n","decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n","\n","#attention inference\n","attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n","decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n","\n","# A dense softmax layer to generate prob dist. over the target vocabulary\n","decoder_outputs2 = decoder_dense(decoder_inf_concat) \n","\n","# Final decoder model\n","decoder_model = Model(\n","    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n","    [decoder_outputs2] + [state_h2, state_c2])"]},{"cell_type":"markdown","metadata":{},"source":["## **Defining an Inference Function for Text Summarization**\n","\n","To make the process of generating summaries from input reviews more accessible and modular, we encapsulate it within a dedicated inference function. This function streamlines the entire inference process, from encoding input reviews to decoding and generating coherent summaries.\n","\n","The key components of this inference function are as follows:\n","\n","1. **Inference Encoder**: Inside this function, we load the trained encoder with its weights to process input reviews. The encoder prepares an initial state that captures the essence of the input text.\n","\n","2. **Inference Decoder**: Our inference function loads the trained decoder, mirroring the architecture used during training. This decoder takes the initial state from the encoder and autoregressively predicts the summary word by word until it reaches an end token.\n","\n","3. **Start Token and End Token**: To signal the beginning and end of a summary, the function uses special tokens. These tokens help in the step-by-step generation of meaningful summaries.\n","\n","4. **Summary Generation**: The heart of the function is the generation of summaries. It takes an input review, encodes it using the inference encoder, and then uses the decoder to produce a coherent and contextually relevant summary.\n","\n","5. **Batch Processing**: Our inference function can handle batch processing, making it suitable for summarizing multiple input reviews simultaneously.\n","\n","By defining this inference function, we simplify the process of utilizing our trained model for text summarization. It provides a clear interface for summarizing text data and can be integrated into various applications where automated summarization is required.\n","\n","This function encapsulates the knowledge and capabilities of our trained model, making it a valuable tool for processing large volumes of text data efficiently.\n"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"6f6TTFnBFxj6","trusted":true},"outputs":[],"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    e_out, e_h, e_c = encoder_model.predict(input_seq)\n","    \n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1,1))\n","    \n","    # Populate the first word of target sequence with the start word.\n","    target_seq[0, 0] = target_word_index['sostok']\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","      \n","        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_token = reverse_target_word_index[sampled_token_index]\n","        \n","        if(sampled_token!='eostok'):\n","            decoded_sentence += ' '+sampled_token\n","\n","        # Exit condition: either hit max length or find stop word.\n","        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1,1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # Update internal states\n","        e_h, e_c = h, c\n","\n","    return decoded_sentence"]},{"cell_type":"markdown","metadata":{},"source":["## **Converting Integer Sequences to Word Sequences**\n","\n","In the context of text summarization, the model primarily operates on integer sequences, where each integer represents a unique word in the vocabulary. To make the output summaries and input reviews more human-readable and accessible, we need a mechanism to convert these integer sequences back into word sequences.\n","\n","This crucial step involves mapping integers to their corresponding words, thus translating the model's predictions and input data into natural language text. The main components of this conversion process are as follows:\n","\n","1. **Integer-to-Word Mapping**: We maintain dictionaries or vocabularies that map integers to their associated words. These dictionaries are created during the data preprocessing stage and are instrumental in both training and inference.\n","\n","2. **Summaries and Reviews**: For both summaries and reviews, we use the respective dictionaries to convert the integer sequences into word sequences. This operation helps us obtain human-readable text that represents the summarization results and the original input.\n","\n","3. **Batch Processing**: Our conversion mechanism is designed to handle batch processing, ensuring that we can efficiently translate multiple sequences simultaneously.\n","\n","By converting integer sequences to word sequences, we bridge the gap between machine-generated outputs and human understanding. This step is crucial for evaluating the quality of summaries and making the summarization results more interpretable and actionable.\n","\n","The ability to effortlessly switch between integer and word representations is a key feature of our text summarization model. It enhances the utility of the model in various applications, where clear and coherent summaries are essential for decision-making and information retrieval.\n"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"aAUntznIFxj9","trusted":true},"outputs":[],"source":["def seq2summary(input_seq):\n","    newString=''\n","    for i in input_seq:\n","        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n","            newString=newString+reverse_target_word_index[i]+' '\n","    return newString\n","\n","def seq2text(input_seq):\n","    newString=''\n","    for i in input_seq:\n","        if(i!=0):\n","            newString=newString+reverse_source_word_index[i]+' '\n","    return newString"]},{"cell_type":"markdown","metadata":{},"source":["## **Displaying Generated Summaries**\n","\n","After training and fine-tuning your text summarization model, it's essential to assess its performance and evaluate the quality of generated summaries. Displaying these summaries is a critical step in understanding how well the model has learned to condense input text into coherent and concise outputs.\n","\n","Key aspects of displaying generated summaries include:\n","\n","1. **Model Evaluation**: Generating summaries from a variety of input texts is an effective way to evaluate the model's performance. It allows you to assess the model's ability to capture the most relevant information and produce meaningful summaries.\n","\n","2. **Comparison to Ground Truth**: In many cases, it's beneficial to compare the model-generated summaries with reference or ground truth summaries. This comparison can help quantify the quality of the generated summaries and identify areas for improvement.\n","\n","3. **Variety in Inputs**: To gain a comprehensive view of the model's capabilities, it's advisable to use a diverse set of input texts. This diversity can include different topics, writing styles, and lengths of input documents.\n","\n","4. **Human Inspection**: Summaries can be displayed for human inspection, allowing researchers, domain experts, or end-users to assess the clarity, coherence, and informativeness of the generated content.\n","\n","5. **Scoring Metrics**: In addition to visual inspection, automated scoring metrics such as ROUGE (Recall-Oriented Understudy for Gisting Evaluation) can be applied to quantify the quality of generated summaries systematically.\n","\n","The act of displaying model-generated summaries provides valuable insights into the strengths and limitations of your text summarization system. It can also guide further refinements and optimizations to enhance the quality of generated content.\n","\n","By presenting these summaries, you enable stakeholders to make informed decisions about the utility and effectiveness of your text summarization model in various applications, such as content summarization, information retrieval, and document analysis.\n"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"BUtQmQTmFxkI","outputId":"f407d9fc-e0cd-4082-98f5-bd1f562dc26f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Review: problems honey sweeteners causing heartburn reading manuka honey thought might different chose brand try quite expensive others unfortunately still gave heartburn tastes awful like cough medicine perhaps something would use taste \n","Predicted summary: bad taste \n","1/1 [==============================] - 0s 146ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Original summary:  great\n","\n","\n","Review: add milk sweetener enjoyable tea unique taste vanilla spice balance expect highly spiced chai \n","Predicted summary: tasty blend \n","1/1 [==============================] - 0s 144ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Original summary:  great\n","\n","\n","Review: really love hint flavors offers water sweet really essence whatever flavor unlike waters add corn syrup flavoring water adds flavor great stuff \n","Predicted summary: love this water \n","1/1 [==============================] - 0s 128ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: year old son loves popcorn always concerned hulls popcorn potential choking hazard little ones popcorn perfect although true hull free popcorn one comes close gets tastes great opinion kid friendly brand popcorn use popcorn machine home \n","Predicted summary: this popcorn is perfect for little ones \n","1/1 [==============================] - 0s 128ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: already like coconut water change mind acquired taste good tried \n","Predicted summary: for only \n","1/1 [==============================] - 0s 123ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: maybe provence cannot taste provencal spices brined green olives also many soft indicates excessive age try another brand next time \n","Predicted summary: eh provence \n","1/1 [==============================] - 0s 140ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: love cook watch cooking shows cable tv one cook england used recipe raved much try glad buttery taste love continue purchase apologize say sooner sincerely kelly \n","Predicted summary: much like corn syrup but better \n","1/1 [==============================] - 0s 121ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: love popcorn love cheese naturally love smartfood popcorn white cheddar flavor delicious eat entire bags actually thinking right write review mouth literally watering anticipating xd popcorn always light fluffy bags actually filled pretty nicely getting money worth favorite part eating smartfood end ton yummy tiny pieces popcorn bottom bag usually cheesiest cannot say enjoy white fingers though \n","Predicted summary: delicious treat \n","1/1 [==============================] - 0s 116ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: fault realize always buy ounce ounce cans buy sale price per ounce normally buy ounce amazon allow return food even though cans still plastic wrap \n","Predicted summary: be sure to check the size \n","1/1 [==============================] - 0s 112ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: says people allergic wheat dairy go without desserts something delicious kind bar almond apricot bars eat dessert \n","Predicted summary: delicious \n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: instructions package atrocious make sense could figure much water use needless say turn well suspect product decent would need better directions many packages experiment determine certain \n","Predicted summary: hard to understand \n","1/1 [==============================] - 0s 118ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: season good flavor good price plan purchase \n","Predicted summary: good buy \n","1/1 [==============================] - 0s 118ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: taste like way higher calories carbs sugar great go want extra protein snack \n","Predicted summary: yum \n","1/1 [==============================] - 0s 131ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Original summary:  great\n","\n","\n","Review: bare fruit great job making healthy junk added organic bake dried fruit stock quick kid snacks emergency packs tasty healthy \n","Predicted summary: no junk dried fruit \n","1/1 [==============================] - 0s 131ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Original summary:  great\n","\n","\n","Review: children gluten free always looking easy delicious snacks get us day big fan envirokids products including crispy rice berry bars soft chewy little bits fruit kids eat feel okay eating almost daily basis many natural ingredients drawback get messy two year old especially tends hold long rice cereal starts come apart get stuck carpet clothes etc still great gluten free product \n","Predicted summary: berry bars are \n","1/1 [==============================] - 0s 124ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Original summary:  great\n","\n","\n","Review: great quick ordinary meal love curry never chance eat fix \n","Predicted summary: great for quick and tastey meal \n","1/1 [==============================] - 0s 141ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: short story like chocolate almond granola miss sticky keep fridge safe keeping \n","Predicted summary: delicious like candy \n","1/1 [==============================] - 0s 106ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: worst tasting banana peppers taste like battery acid water dull acid even taste good hot hint people taste spit trash would even take free got jars waste money shocked badly taste got bad batch sorry jars tried bad tasting rather eat grass vinegar \n","Predicted summary: wow these make me want to gag \n","1/1 [==============================] - 0s 117ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: using bottles month problems breaking leaking unless put nipple wrong complaint grips melted microwave steam bag recall instructions specifically say use steam bags problem might fault bottle evenflo would recommend fact told husband need bottles stick inexpensive stupid extra parts wash lose melt dishwasher replacement nipples dirt cheap compared bottles \n","Predicted summary: inexpensive bottles that get the job done \n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Original summary:  great\n","\n","\n","Review: numi vision inspire well mind body spirit simple art tea awful lot tea take give credit setting goal cannot say transformed tasty chocolate tea say soothing pretty yummy enough chocolate vanilla bean taste satisfy small chocolate craving enough make tea sweet good way small treat hints chocolate end day avoid caloric damage real chocolate treats tea aficionado comment tea quality beyond fact clearly lipton company image producing quality product go stars tasty flavor really wait cup tea \n","Predicted summary: for tea \n","1/1 [==============================] - 0s 105ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: best mix found makes great bread sticks wonderful calzones make batch freeze ready cook works well toaster oven well regular oven daughter cannot eat gluten really missed bread stuff perfect replacement used chebe mixes disappointed everyone gf knows things different taste texture really close old things used love think like well especially great find help make transition year old give thumbs know got good \n","Predicted summary: delicious \n","1/1 [==============================] - 0s 112ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: regularly eat cereals breakfast champions occasionally snacks like mixed milk morning dry times one think comparable cheerios except looks twice big glazed sprinkled peanuts interesting comparisons crunchy nut cheerios crunchy nut calories cheerios calories vs sodium vs potassium vs dietary fiber allergy concerns crunchy nut peanuts wheat traces soybeans may contain tree nuts cheerios almonds may contain wheat ingredients tastes great time tell also regular staple household \n","Predicted summary: it tastes great \n","1/1 [==============================] - 0s 120ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: love chicken base delicious use make soups also use give extra flavor steaming veggies rub whole chicken turkey baking yum \n","Predicted summary: the best cooking ingredient there is \n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: dog loves chicken steak peanut butter booda bones fond spearmint peppermint variety dog eat offered dad dog often sit even touch would recommend dog prefers meat \n","Predicted summary: dog is not fan \n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Original summary:  great\n","\n","\n","Review: odd calories gatorade new nutrition shake works great meal replacement also packs nice protein per shake nice need easy way get protein vanilla flavor shake quite good think palatable slimfast drink tasty none weird protein shake aftertaste think drinking time could get bit pricey would definitely recommend people weight lifting workout regimen looking easy way get protein meal replacement \n","Predicted summary: great as meal replacement \n","1/1 [==============================] - 0s 118ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: master cleanse twice year tried grade syrups best tasting one far wife prefers brand tastes less sweet little kick lemonade \n","Predicted summary: best for the master cleanse \n","1/1 [==============================] - 0s 117ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: tinkyada makes excellent pasta regardless whether must eat gluten free mushy gritty one reviewer noted properly cooked perfectly al dente disappointed \n","Predicted summary: better than wheat pasta \n","1/1 [==============================] - 0s 118ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: love cinnamon tea hard time finding ordered sent right away complaints \n","Predicted summary: tea everything expected \n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: pods good decaf espresso entirely like real espresso want one dinner worried falling asleep later great delivery quick professional \n","Predicted summary: good decaf \n","1/1 [==============================] - 0s 118ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Original summary:  great\n","\n","\n","Review: one best teas found keurig rich smooth satisfying taste buying \n","Predicted summary: celestial seasonings english breakfast black tea keurig cups count \n","1/1 [==============================] - 0s 119ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Original summary:  great\n","\n","\n","Review: bought recently disappointed earth best general good giving variety bulk packs main point us purchasing jarred foods variety yet jars pack banana sure considered variety would buy mainly bananas cheap easy feed toddler would want gouged mark also see label stage consistency stage food \n","Predicted summary: not really variety pack \n","1/1 [==============================] - 0s 116ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: newman pods keurig brewers wonderful well easy use ordering run like coffee strong bold yet smooth enjoy coffee ya love easy \n","Predicted summary: great coffee for your keurig coffee maker \n","1/1 [==============================] - 0s 112ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Original summary:  great\n","\n","\n","Review: dried cherries taste ok thought funny oily first impression discovered ingredient label included sunflower oil apple juice needless say disappointed product advertised good deal natural foods diet something seem natural adding oil juice already great tasting fruit \n","Predicted summary: added ingredients \n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Original summary:  great\n","\n","\n","Review: dogs small rat terrier large old english sheepdog celebrated first birthday love dog food slightly higher fat content many dog foods pups tummy troubles skin issues dog food \n","Predicted summary: my dogs love it \n","1/1 [==============================] - 0s 116ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: love pho could eat time problem pho good health issues require low sodium low carbs comes happy pho happy stuff great could eat times week \n","Predicted summary: love the taste and the \n","1/1 [==============================] - 0s 135ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: super transaction ordered father law birthday thrilled really fresh tasted amazing thanks \n","Predicted summary: excellent \n","1/1 [==============================] - 0s 117ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Original summary:  great\n","\n","\n","Review: writing eaten soup lunch something gone terribly wrong enjoyed soup quite frequently past fairly recently soup consistently good taste correct right amount sherry enough turtle satisfy normally generous standards last serving prompted search internet source problem turtle far much tomato alluded earlier consistent past history product something gone terribly wrong \n","Predicted summary: something has changed \n","1/1 [==============================] - 0s 128ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: happy panettone extremely dry brands past much better less expensive breads would purchase \n","Predicted summary: not so good \n","1/1 [==============================] - 0s 117ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Original summary:  great\n","\n","\n","Review: bought boxes ahmad fruit tea husband going tea kick gift cat father day year ago good tea flavors true use iced tea summer delicious hot cold definitely buying \n","Predicted summary: great hot or iced \n","1/1 [==============================] - 0s 114ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: kids gobbled snack sized packets caramel popcorn loved packs mind giving popcorn either portioned nicely perfect lunchboxes school snacks cannot wait try flavors \n","Predicted summary: gobble gobble \n","1/1 [==============================] - 0s 134ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 32ms/step\n","Original summary:  great\n","\n","\n","Review: absolutely delicious although cheesy like dress ingredients mushrooms broccoli easy make delicious \n","Predicted summary: delicious \n","1/1 [==============================] - 0s 132ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Original summary:  great\n","\n","\n","Review: cat allergic food tried cook buy food even refuse eat treats royal canin food would eat without allergic reaction make sure change water least day cat drinks planty \n","Predicted summary: cat loves it \n","1/1 [==============================] - 0s 169ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Original summary:  great\n","\n","\n","Review: enjoyed old fashioned licorice taste sugar free hard candy seem nasty side effects sugar free candies exhibit \n","Predicted summary: great sugar free licorice hard candy \n","1/1 [==============================] - 0s 157ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Original summary:  great\n","\n","\n","Review: lucy cookies track record buying cocoa suppliers use child labor farm cocoa beans avoid product conscience \n","Predicted summary: use cocoa from labor \n","1/1 [==============================] - 0s 142ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Original summary:  great\n","\n","\n","Review: first like vegemite must carry one two purse time \n","Predicted summary: love it \n","1/1 [==============================] - 0s 131ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 37ms/step\n","Original summary:  great\n","\n","\n","Review: know jack link excellent product dates excellent never find better price anywhere go ahead sign autoship enjoy healthy protein anytime jack link beef steak teriyaki ounce packages \n","Predicted summary: best price you will ever find \n","1/1 [==============================] - 0s 153ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Original summary:  great\n","\n","\n","Review: second time ordered raisins like snack oatmeal tell nd order fresher st order really enjoy \n","Predicted summary: raisins \n","1/1 [==============================] - 0s 141ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Original summary:  great\n","\n","\n","Review: local health food store sells chia seeds pound great find high quality product around pound go one pound bags per month much reasonable option add nutritious item diet \n","Predicted summary: great product at great price \n","1/1 [==============================] - 0s 149ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: decided wanted get husband son try something new already enjoy couscous sure would like plain picked grocery store thinking would compliment chicken curry wow tasted amazing gave son first finicky eater demolished wanted finished serving husband long story short people get boxes leftovers \n","Predicted summary: awesome \n","1/1 [==============================] - 0s 134ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Original summary:  great\n","\n","\n","Review: huge fan quaker chewy bars long time converted coffee flavor fantastic noticeable overwhelm chocolate flavor really look forward eating last long around house unlike reviewers noticed significant increase time spent throne room pretty young either digestive system adapts quickly less observant either way problems would quit eating since everybody different though would recommend trying week schedule routine road trip digestive change comfortable surroundings happy munching \n","Predicted summary: better than quaker \n","1/1 [==============================] - 0s 140ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Original summary:  great\n","\n","\n","Review: makes excellent bisquits minimum work reheated leftovers good fresh packaging perfect small medium large families \n","Predicted summary: gets my vote \n","1/1 [==============================] - 0s 123ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Original summary:  great\n","\n","\n","Review: idea cookies ordering process box add message yet see packaging ask weeks later received embarassing \n","Predicted summary: message was not included \n","1/1 [==============================] - 0s 160ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Original summary:  great\n","\n","\n","Review: gotten really hooked using ham base split pea ham soup label ratio tbsp qt water plenty may even bit overpowering depending taste makes \n","Predicted summary: gr \n","1/1 [==============================] - 0s 135ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: love taste honey times need energy boost eager try honey filled drops flavor good sure deliver energy part package says drops equal dv vitamins said love honey lozenges lot get seem convenient maybe ate one afternoon dont see row update try \n","Predicted summary: confusing concept \n","1/1 [==============================] - 0s 129ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Original summary:  great\n","\n","\n","Review: rawhide rolls great hard time finding roll last longer hour dog actually took dog day finish \n","Predicted summary: long lasting \n","1/1 [==============================] - 0s 147ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: cappuccino flavor drink absolutely loved huge flavor strong taste much sweetness bit overpowering tastes cappuccino flavored oz thought bit small flavor even smaller oz although like ready made coffee drink think stick cappuccino ones \n","Predicted summary: very strong didn care for it \n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: ordered rolands giant snails three find superb superb price \n","Predicted summary: roland escargots are excellent \n","1/1 [==============================] - 0s 155ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: husband loves strong caribou coffee like milder one drink caribou kinds great coffee strong disappoint \n","Predicted summary: caribou coffee strong \n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: yeast failed batches soda beer yet keep using exclusively may try yeasts become seasoned stick works \n","Predicted summary: very effective \n","1/1 [==============================] - 0s 109ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: looking low carb pasta tried shirataki pasta like texture heard pasta internet research decided try cooking better cook shorter amount time makes low carb also one thing read reheating pasta mess chemical balance sure true would stay safe side would recommend cooking ready eat reheating sure really low carb absolute way find also work every one trying buy six boxes would good idea would recommend friend trying watch carb intake \n","Predicted summary: happy with this product \n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: looking popcorn salt long time love popcorn longer sold grocery stores thing could find grocery stores butter flavoring delighted find real popcorn salt finely ground works great looking \n","Predicted summary: yes real popcorn salt \n","1/1 [==============================] - 0s 114ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Original summary:  great\n","\n","\n","Review: excellent quality bottles plastic chemicals good price quality product \n","Predicted summary: excellent quality \n","1/1 [==============================] - 0s 110ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Original summary:  great\n","\n","\n","Review: drunk bit coffee done experimentation home grinder espresso machine always come back illy go past perfect every time \n","Predicted summary: best coffee on the planet \n","1/1 [==============================] - 0s 122ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Original summary:  great\n","\n","\n","Review: tried lyndt dark chocolate truffles readily available grocery even purchased box lyndt amazon looking reorder noted ingredients lyndt vs chocmod chocmod hands natural free artificial flavorings type personality ordered boxes wrong would sorry bitter taste initial outset melt mouth glories intense chocolate flavor immediately followed creamy dreamy chocolate experience going pack next time satisfied one whereas lyndt cannot believe great price grams much better bang buck better option \n","Predicted summary: out of this world \n","1/1 [==============================] - 0s 116ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: perhaps got lucky delighted product turned received order black pearls today promptly cooked batch boiled twenty minutes stirring constantly let cool ten minutes still stirring frequently drained rinsed cold water let sit cold water short time made first batch tea using decaf herbal tea coconut milk liquid stevia oh yum pearls perfect chewy texture tea sweet smooth great product even come giant quantity think daughter trouble consuming \n","Predicted summary: awesome \n","1/1 [==============================] - 0s 123ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Original summary:  great\n","\n","\n","Review: purchased indoor adult formula accident using royal canin dry cat food indoor mature formula pound bag one older cats found cats liked formula much mature cat formula senior cat passed continued buying indoor adult middle aged cats really like taste waste products seem reduced smelly like cheaper foods also rarely throw food foods seemed like weekly occurence know expensive feel high quality keep buying kitties \n","Predicted summary: my cats really like this food \n","1/1 [==============================] - 0s 121ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Original summary:  great\n","\n","\n","Review: ever happen tuna solid use mean solid white use mean white cans smaller price expensive biggest complaint additives soy proteins something added cannot drain water anymore rinse rinse done miserable mess solid white tuna brand bad cos starkist going try natural tongol tuna next time little expensive hopefully better \n","Predicted summary: meh \n","1/1 [==============================] - 0s 123ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Original summary:  great\n","\n","\n","Review: one sip child severe allegic reaction throat swelling difficulty breathing take good look put junk \n","Predicted summary: severe allergic reaction \n","1/1 [==============================] - 0s 112ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Original summary:  great\n","\n","\n","Review: horrible gross tasting tea bad threw away taste cross rancid dirt chicago tea garden good oolong tea good choice private reserve monkey picked oolong tea outstanding waste money junk \n","Predicted summary: do not buy it \n","1/1 [==============================] - 0s 136ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: yorkshire gold one favorite breakfast teas like tea strong use two heaping measuring teaspoons ounce tea pot pot boiling water one minute empty pot add tea fill pot boiling water let tea steep minutes meanwhile nuke little milk microwave mug add tea mug together packet splenda result excellent mug breakfast tea malty rich tasting may refined flavor teas one buy specialty tea website great price \n","Predicted summary: one of the best breakfast teas \n","1/1 [==============================] - 0s 147ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Original summary:  great\n","\n","\n","Review: bought brother loves cokes lime syrup gas stations mentioned would cheaper could make home could find sweet syrup stores brother loves monin lime syrup says even better gas stations thanks monin \n","Predicted summary: great lime syrup \n","1/1 [==============================] - 0s 114ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: hoping make peppermint lattes home syrup hardly taste even straight much less coffee kept adding coffee could taste peppermint finally put spoon tried straight understood bland peppermint syrup try another brand threw one away \n","Predicted summary: not much peppermint \n","1/1 [==============================] - 0s 106ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Original summary:  great\n","\n","\n","Review: dolce gusto piccolo machine tassimo coffee maker tried making cappuccinos machines far prefer dolce gusto palate much authentic cappuccino tast think dolce gusto machine uses high pressure bar system tassimo tassimo make delicious drip style coffee especially starbucks selections generally like sweetened coffee drinks main difference dolce gusto cappuccino skinny cappuccino seems sweetner added milk capsule regular cappuccino really look forward daily dolce gusto skinny cappuccino highly recommend product \n","Predicted summary: cappuccino delicioso \n","1/1 [==============================] - 0s 125ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Original summary:  great\n","\n","\n","Review: going try popcorn suppose gift although arrived box stuffed smaller box saying box messed give gift popping popcorn expected taste like bacon give three sent mainly although taste like bacon still bad tasting popcorn \n","Predicted summary: bad packaging not what expected \n","1/1 [==============================] - 0s 122ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Original summary:  great\n","\n","\n","Review: mex grocer shipped order fast product widely unavailable us product tastes like pear seeds edible like seller product \n","Predicted summary: guava just like pear \n","1/1 [==============================] - 0s 117ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Original summary:  great\n","\n","\n","Review: mini marshmallows needed get us tough cold winter never enough marshmallows store bought hot cocoa mix perfect economical way fix issue pleased quality definitely buying seller near future highly recommended treasure cute tiny marshmallows hot cocoa \n","Predicted summary: great deal \n","1/1 [==============================] - 0s 108ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: using product years absolutely love use everything steak pork chicken fish cannot go wrong \n","Predicted summary: best steak salt around \n","1/1 [==============================] - 0s 103ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: mrs balls hot first discovered mrs ball trip england years ago fell love alas brought one bottle home pre internet get really delicious chutney hot smooth comparison others mild chunky major grey flavor right heavy handed strong spices like cloves leave tinny aftertaste enough heat make sit take notice new chutney like things bit spicy give try good curries excellent spread cream cheese thinned little juice makes delicious baste pork roast great product \n","Predicted summary: wake up your taste buds \n","1/1 [==============================] - 0s 108ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: stevia affordable concerned would inferior pleased flavor quality extremely pleased price \n","Predicted summary: it is stevia \n","1/1 [==============================] - 0s 105ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: love texture coffee bitterness smooth need cream cut flavor usually coffee drinker friend told one best ever intended christmas gift curiosity bought one include bags know difference believe thought instant tasted way better real coffee cup java almost tempted give rest coffee away also shipment fast ordered items coffee came within week items come infact every time checked progress amazon kept pushing items away shipment date could understand cancel rest order buy items elsewhere go figure \n","Predicted summary: great coffee \n","1/1 [==============================] - 0s 109ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: bar pretty good chocolate taste true chocolate bit strange aftertaste unbearable definitely tastes like health food always bad thing expecting think bar replace snickers sorely disappointed health nut looking sweet snack give try \n","Predicted summary: pretty good bar \n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: price great teas individually wrapped plus since exterior box mine torn tapped places tired yet box says use cups water \n","Predicted summary: good price \n","1/1 [==============================] - 0s 112ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Original summary:  great\n","\n","\n","Review: love mints strong regular altoids seem difficult find stores great amazon bulk purchase \n","Predicted summary: great mints \n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: two six packages beginning mold even close expiration date one package visibly torn curious see packs still sealed air tight placed water five packs exposed air small opening around seal imagine burst somewhere travels changes altitude pressure cannot vouch actually taste product eat silver lining amazon great customer service \n","Predicted summary: not good amazon purchase \n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: wife brew drink cup senseo medium roast coffee everyday done years almost always buy amazon com find price best \n","Predicted summary: every day treat \n","1/1 [==============================] - 0s 107ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: good reviews amazon coupon purchased enchilada soup mix try give small christmas gifts cooked crock pot today veggie fake chicken strips flavor vegetables really nothing hope quite come full boil crock pot next one highly doctor vegetables rotel let come complete boil putting low nice thick \n","Predicted summary: meh \n","1/1 [==============================] - 0s 105ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: thank amazon carrying favorites especially ones cannot buy locally service good products arrive promptly \n","Predicted summary: lipton soup \n","1/1 [==============================] - 0s 107ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n","Review: daughter love rusks one year old eating since months old wish known organic variety available definitely recommend mom wanting worry free finger food little one \n","Predicted summary: awesome first finger food \n","1/1 [==============================] - 0s 104ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Original summary:  great\n","\n","\n","Review: others said valve pops sprays everywhere hopefully water getting sprayed residual bug \n","Predicted summary: should be called user gon \n","1/1 [==============================] - 0s 110ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: everyday tea great favor black tea pricing amazon much lower stores drink tea everyday getting bulk great \n","Predicted summary: great black tea \n","1/1 [==============================] - 0s 108ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: unfortunately basically everything box horrible yogurt pretzels stale caramels tasted like chalk popcorn pretty bad liked milk chocolate truffles three box save money trouble spend better elsewhere \n","Predicted summary: worst valentines day gift ever \n","1/1 [==============================] - 0s 119ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: looked vain locally hansen orange mango soda found amazon really appreciate able enjoy soda regular basis would recommend anyone natural ingredients sweetened sugar plain ordinary sugar \n","Predicted summary: thank you amazon com \n","1/1 [==============================] - 0s 107ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: dudes live bahamas love purchase anything little cheaper us dollars come pay dollars theses wth well aint purchasing way price rediculous leave comment \n","Predicted summary: kids love these but whats the deal with the \n","1/1 [==============================] - 0s 108ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: pecans salty sweet glaze rich usually hard time stopping comes praline pecans felt compelled open second bag setting thick coating pretty hard mouth little raw eating ounce bag pecans good quality eat slight bitter taste prefer brand praline pecan one local stores use premium pecans perfect texture lighter glaze sweet salty decided try pecans brand full price ounces finish pralines going back store brand \n","Predicted summary: ok snack but will not buy again \n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: licorice really good took work everyone agreed really good stuff things gotta add though fan pomegranate really liked surprised tasted good also stuff delivered house hottest weather week year even came close setting record get chance check mail days sat outside mailbox degree heat day expected big lump licorice newman apparently recipe perfectly dealing temperature none stuck together would buy bet would cannot wait try flavors \n","Predicted summary: awesome stuff \n","1/1 [==============================] - 0s 105ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","Original summary:  great\n","\n","\n","Review: pretty cheap sure going get feel like pretty weak alot like gas station cappuccinos machine strong like calories nice low calorie treat dieting \n","Predicted summary: not the worst but not the best \n","1/1 [==============================] - 0s 109ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: tried generic brands keep coming back honey maid kids say taste better agree honey flavor apparent others taste bit cardboard like comparison use generic brands make graham cracker crust noticeable used recipes snacks stick honey maid \n","Predicted summary: favorite with my kids \n","1/1 [==============================] - 0s 109ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: ordered one box ended getting subscription less cost per box one every months great \n","Predicted summary: great cherries \n","1/1 [==============================] - 0s 109ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: baby really loves eat come glass great discontinued using found web posting manufacturer uses lids contain bpa emailed customer service department company confirmed bpa used lids smacks worst kind marketing taking advantage organic label potential health benefits selling inferior packaging legal yes really spirit organic movement pete sake lid word organic written times stopped using companies products including dry oatmeal rice personally found dishonest practice summary good food bad implementation \n","Predicted summary: organic but bpa in the lid \n","1/1 [==============================] - 0s 108ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Original summary:  great\n","\n","\n","Review: love percolated coffee best filters could find store thanks amazon \n","Predicted summary: no grounds \n","1/1 [==============================] - 0s 112ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 22ms/step\n","Original summary:  great\n","\n","\n"]}],"source":["for i in range(0,100):\n","    print(\"Review:\",seq2text(x_tr[i]))\n","    print(\"Predicted summary:\",seq2summary(y_tr[i]))\n","    print(\"Original summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
